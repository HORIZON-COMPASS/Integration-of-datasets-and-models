{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Table of Contents\n",
        "1. [Context](#Context)\n",
        "2. [Step by Step Guide](#Step-by-Step-Guide)\n",
        "\n",
        "    2.1. [Obtaining and loading data](#Step-1-Obtaining-and-loading-data)\n",
        "\n",
        "    2.2. [ERA5 and ERA5-Land processing](#step-2-era5-and-era5-land-data-processing)\n",
        "\n",
        "    2.3. [EMO-1 data processing](#step-3-emo-1-data-processing)\n",
        "\n",
        "    2.4. [Data merging](#step-4-data-merging)\n",
        "\n",
        "    2.5. [Processing of combined ERA5-Land for BASD](#step-5-processing-of-combined-era5-land-for-bias-adjustment)\n",
        "\n",
        "    2.6. [Processing of combined EMO-1](#step-6-processing-of-combined-emo-1-data)\n",
        "\n",
        "    2.7. [Processing of combined EMO-1 for BASD](#step-7-processing-of-combined-emo-1-data-for-bias-adjustment)\n",
        "\n",
        "    2.8. [Bias-adjustment and statistical downscaling](#step-8-bias-adjustment-and-statistical-downscaling)\n",
        "\n",
        "    2.9. [Convert Bias-adjusted and downscaled ERA5 to EMO-1 format](#step-9-convert-bias-adjusted)\n",
        "\n",
        "    2.10. [Final post-processing of ERA-5 files for consistency with EMO-1 data](#step-10-final-post-processing)\n",
        "    \n",
        "3. [Possible fixes to common issues](#possible-fixes)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "# Context\n",
        "<a id=\"Context\"></a>\n",
        "This notebook will provide a step-by-step guide to perform bias adjustment and statistical downscaling with ISIMIP3BASD, ERA-5 Land, and EMO-1. Each step accompanies the code, explanation along with the necessary libraries required to run the code. To run the code, it is recommended to have Python version **3.11.6** installed along with the **Jupyter** Notebook extension.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step by Step Guide\n",
        "<a id=\"Step-by-Step-Guide\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Workflow for merged all data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"width:100%; display:block;\">\n",
        "    <div style=\"width:50%;\"><img src=\"https://naturalhazards.eu/workflow.jpg\"></div>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Workflow for yearly data\n",
        "\n",
        "<div style=\"width:100%; display:block;\">\n",
        "    <div style=\"width:50%;\"><img src=\"https://naturalhazards.eu/workflow2.jpg\"></div>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1. Obtaining and loading data\n",
        "<a id=\"Step-1-Obtaining-and-loading-data\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we need to download ERA-5 Land data from Copernicus Marine API. To access ERA-5 Land data via the Copernicus Marine API, you'll need to access it through the Copernicus Climate Data Store (CDS) API.\n",
        "\n",
        "1. Go to the [Copernicus Climate Data Store](https://cds.climate.copernicus.eu/#!/home).\n",
        "\n",
        "2. Create an account by registering if you haven't done so already.\n",
        "\n",
        "3. Install the cdsapi\n",
        "\n",
        "4. After registering, you'll receive an API key. This key needs to be saved in a .cdsapirc file in your home directory (~/.cdsapirc). More details on [https://cds.climate.copernicus.eu/how-to-api]\n",
        "\n",
        "5. Replace your_username and your_api_key with your actual username and API key from your CDS account.\n",
        "\n",
        "6. Accept the \"Terms of use\" on the end of the manage licenses page: [https://cds.climate.copernicus.eu/datasets/reanalysis-era5-land?tab=download#manage-licences]\n",
        "\n",
        "The cdsapi is a Python package that allows you to download data programmatically.\n",
        "\n",
        "Install the cdsapi by running the following command"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "pip install cdsapi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The **.cdsapirc** file should look like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "url: https://cds.climate.copernicus.eu/api/v2\n",
        "key: your_username:your_api_key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can now use the CDS API to download the ERA-5 Land data using the below code. You need to replace the relative path in the code with the path of your local directory where you would like to save the downloaded files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_dir = 'YOUR-LOCATION/compass_framework'  # Keep location of Python to compass_framework folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import cdsapi\n",
        "import os\n",
        "\n",
        "c = cdsapi.Client()\n",
        "\n",
        "years = range(2024, 2025)\n",
        "months = range(1, 2)\n",
        "\n",
        "for y in years:\n",
        "    for m in months:\n",
        "        era5land_file = os.path.join(output_dir, 'step_1', 'ERA5Land_' + str(y) + '_' + str(m) + '.grib')\n",
        "        if os.path.isfile(era5land_file):\n",
        "            print('Already downloaded:', era5land_file)\n",
        "        else:\n",
        "            c.retrieve(\n",
        "                'reanalysis-era5-land',\n",
        "                {\n",
        "                    'variable': [\n",
        "                        '10m_u_component_of_wind', '10m_v_component_of_wind', '2m_dewpoint_temperature',\n",
        "                        '2m_temperature', 'surface_solar_radiation_downwards', 'total_precipitation'\n",
        "                    ],\n",
        "                    'year': str(y),\n",
        "                    'month': str(m),\n",
        "                    'day': [\n",
        "                        '01', '02', '03', '04', '05', '06', '07', '08', '09',\n",
        "                        '10', '11', '12', '13', '14', '15', '16', '17', '18',\n",
        "                        '19', '20', '21', '22', '23', '24', '25', '26', '27',\n",
        "                        '28', '29', '30', '31',\n",
        "                    ],\n",
        "                    'time': [\n",
        "                        '00:00', '01:00', '02:00', '03:00', '04:00', '05:00',\n",
        "                        '06:00', '07:00', '08:00', '09:00', '10:00', '11:00',\n",
        "                        '12:00', '13:00', '14:00', '15:00', '16:00', '17:00',\n",
        "                        '18:00', '19:00', '20:00', '21:00', '22:00', '23:00',\n",
        "                    ],\n",
        "                    'area': [\n",
        "                        55, 13, 48, 26,  # Poland and catchments of Polish rivers\n",
        "                    ],\n",
        "                    'format': 'grib',\n",
        "                },\n",
        "                era5land_file)\n",
        "\n",
        "        era5_file = os.path.join(output_dir, 'step_1', 'ERA5_' + str(y) + '_' + str(m) + '.grib')\n",
        "        if os.path.isfile(era5_file):\n",
        "            print('Already downloaded:', era5_file)\n",
        "        else:\n",
        "            c.retrieve(\n",
        "                'reanalysis-era5-single-levels',\n",
        "                {\n",
        "                    'product_type': 'reanalysis',\n",
        "                    'variable': [\n",
        "                        '10m_u_component_of_wind', '10m_v_component_of_wind', '2m_dewpoint_temperature',\n",
        "                        '2m_temperature', 'surface_solar_radiation_downwards', 'total_precipitation'\n",
        "                    ],\n",
        "                    'year': str(y),\n",
        "                    'month': str(m),\n",
        "                    'day': [    \n",
        "                        '01', '02', '03', '04', '05', '06', '07', '08', '09',\n",
        "                        '10', '11', '12', '13', '14', '15', '16', '17', '18',\n",
        "                        '19', '20', '21', '22', '23', '24', '25', '26', '27',\n",
        "                        '28', '29', '30', '31',\n",
        "                    ],  \n",
        "                    'time': [   \n",
        "                        '00:00', '01:00', '02:00', '03:00', '04:00', '05:00',\n",
        "                        '06:00', '07:00', '08:00', '09:00', '10:00', '11:00',\n",
        "                        '12:00', '13:00', '14:00', '15:00', '16:00', '17:00',\n",
        "                        '18:00', '19:00', '20:00', '21:00', '22:00', '23:00',\n",
        "                    ],  \n",
        "                    'area': [   \n",
        "                        55, 13, 48, 26,\n",
        "                    ],  \n",
        "                    'format': 'grib',\n",
        "                },\n",
        "                era5_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Table: Description of the ERA5 and ERA5-Land variables.**\n",
        "\n",
        "| Short Name | Full Name                                   | Description                                                                                           |\n",
        "|------------|---------------------------------------------|-------------------------------------------------------------------------------------------------------|\n",
        "| `u10`      | 10m U Component of Wind                     | The eastward (u) component of the wind at 10 meters above ground level.                             |\n",
        "| `v10`      | 10m V Component of Wind                     | The northward (v) component of the wind at 10 meters above ground level.                            |\n",
        "| `dewpoint_temperature` | 2m Dewpoint Temperature              | The dew point temperature at 2 meters above ground level.                                            |\n",
        "| `t2m`      | 2m Temperature                              | The air temperature at 2 meters above ground level.                                                  |\n",
        "| `ssrd`    | Surface Solar Radiation Downwards          | The amount of solar radiation reaching the Earth's surface.                                          |\n",
        "| `tp`       | Total Precipitation                        | The total amount of precipitation (rain, snow, etc.) over a given period.                           |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once the data has finished downloading, it is now ready for processing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2. ERA5 and ERA5-Land data processing\n",
        "<a id=\"Step-2-ERA5processing\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The script below will automate the necessary processing of downloaded ERA5-Land climate data for each year from 1950 to 2023. It converts monthly GRIB files into daily NetCDF files, calculates various climate variables (temperature, precipitation, solar radiation, wind speed, relative humidity), and performs necessary adjustments and cleanup. \n",
        "\n",
        "**NOTE:**: You must have the following libraries installed:\n",
        "1. `cdo` either by sudo apt-get install cdo or follow the official documentation.\n",
        "2. Make sure the bash is updated by use of sudo apt update if you are using WSL2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "for y in {2023..2024}\n",
        "do\n",
        "    year=\"$y\"\n",
        "    year_n=\"$((y+1))\"\n",
        "    i1=\"${output_dir}/step_1/ERA5Land_${year}_1.grib\"\n",
        "    i2=\"${output_dir}/step_1/ERA5Land_${year}_2.grib\"\n",
        "    i3=\"${output_dir}/step_1/ERA5Land_${year}_3.grib\"\n",
        "    i4=\"${output_dir}/step_1/ERA5Land_${year}_4.grib\"\n",
        "    i5=\"${output_dir}/step_1/ERA5Land_${year}_5.grib\"\n",
        "    i6=\"${output_dir}/step_1/ERA5Land_${year}_6.grib\"\n",
        "    i7=\"${output_dir}/step_1/ERA5Land_${year}_7.grib\"\n",
        "    i8=\"${output_dir}/step_1/ERA5Land_${year}_8.grib\"\n",
        "    i9=\"${output_dir}/step_1/ERA5Land_${year}_9.grib\"\n",
        "    i10=\"${output_dir}/step_1/ERA5Land_${year}_10.grib\"\n",
        "    i11=\"${output_dir}/step_1/ERA5Land_${year}_11.grib\"\n",
        "    i12=\"${output_dir}/step_1/ERA5Land_${year}_12.grib\"\n",
        "    i13=\"${output_dir}/step_1/ERA5Land_${year_n}_1.grib\"\n",
        "    o_tas=\"${output_dir}/step_2/ERA5_land_daily/tas_ERA5_${year}.nc\"\n",
        "    o_tasmin=\"${output_dir}/step_2/ERA5_land_daily/tasmin_ERA5_${year}.nc\"\n",
        "    o_tasmax=\"${output_dir}/step_2/ERA5_land_daily/tasmax_ERA5_${year}.nc\"\n",
        "    o_t_dew=\"${output_dir}/step_2/ERA5_land_daily/dew_ERA5_${year}.nc\"\n",
        "    o_sfcWind=\"${output_dir}/step_2/ERA5_land_daily/sfcWind_ERA5_${year}.nc\"\n",
        "    o_rsds=\"${output_dir}/step_2/ERA5_land_daily/rsds_ERA5_${year}.nc\"\n",
        "    o_pr=\"${output_dir}/step_2/ERA5_land_daily/pr_ERA5_${year}.nc\"\n",
        "    o_rsds_t=\"${output_dir}/step_2/ERA5_land_daily/rsds_t_ERA5_${year}.nc\"\n",
        "    o_pr_t=\"${output_dir}/step_2/ERA5_land_daily/pr_t_ERA5_${year}.nc\"\n",
        "    o_hurs=\"${output_dir}/step_2/ERA5_land_daily/hurs_ERA5_${year}.nc\"\n",
        "\n",
        "    cdo -f nc -daymean -selname,var167 -mergetime $i1 $i2 $i3 $i4 $i5 $i6 $i7 $i8 $i9 $i10 $i11 $i12 $o_tas\n",
        "    cdo -f nc -daymin -selname,var167 -mergetime $i1 $i2 $i3 $i4 $i5 $i6 $i7 $i8 $i9 $i10 $i11 $i12 $o_tasmin\n",
        "    cdo -f nc -daymax -selname,var167 -mergetime $i1 $i2 $i3 $i4 $i5 $i6 $i7 $i8 $i9 $i10 $i11 $i12 $o_tasmax\n",
        "    cdo -f nc expr,rsds=\"var169/86400\" -selhour,0 -selname,var169 -mergetime $i1 $i2 $i3 $i4 $i5 $i6 $i7 $i8 $i9 $i10 $i11 $i12 $i13 $o_rsds_t\n",
        "    cdo -f nc expr,pr=\"var228/86.4\" -selhour,0 -selname,var228 -mergetime $i1 $i2 $i3 $i4 $i5 $i6 $i7 $i8 $i9 $i10 $i11 $i12 $i13 $o_pr_t\n",
        "    cdo selyear,$y -shifttime,-1days $o_rsds_t $o_rsds\n",
        "    cdo selyear,$y -shifttime,-1days $o_pr_t $o_pr\n",
        "    cdo -f nc -daymean -selname,var168,var167 -mergetime $i1 $i2 $i3 $i4 $i5 $i6 $i7 $i8 $i9 $i10 $i11 $i12 $o_t_dew\n",
        "    cdo expr,hurs=\"(10 ^ (7.5 * (var168-273.15) / (237.3+(var168-273.15)))) / (10 ^ (7.5 * (var167-273.15) / (237.3+(var167-273.15)))) * 100\" $o_t_dew $o_hurs\n",
        "    cdo -f nc expr,sfcWind=\"sqrt(var165*var165+var166*var166)\" -daymean -selname,var165,var166 -mergetime $i1 $i2 $i3 $i4 $i5 $i6 $i7 $i8 $i9 $i10 $i11 $i12 $o_sfcWind\n",
        "    rm $o_rsds_t\n",
        "    rm $o_pr_t\n",
        "    rm $o_t_dew\n",
        "\n",
        "done\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, in the similar way, run the script below will automate the necessary processing of downloaded ERA5 climate data for each year from 1950 to 2023. It converts monthly GRIB files into daily NetCDF files, calculates various climate variables (temperature, precipitation, solar radiation, wind speed, relative humidity), and performs necessary adjustments and cleanup. Similarly, replace {your path} with your local directory path.\n",
        "\n",
        "This data will be helpful to gap-fill the ERA5-Land data in later stages of the workflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "for y in {1950..2023}\n",
        "do\n",
        "    year=\"$y\"\n",
        "    i1=\"${output_dir}/step_1/ERA5_${year}_1.grib\"\n",
        "    i2=\"${output_dir}/step_1/ERA5_${year}_2.grib\"\n",
        "    i3=\"${output_dir}/step_1/ERA5_${year}_3.grib\"\n",
        "    i4=\"${output_dir}/step_1/ERA5_${year}_4.grib\"\n",
        "    i5=\"${output_dir}/step_1/ERA5_${year}_5.grib\"\n",
        "    i6=\"${output_dir}/step_1/ERA5_${year}_6.grib\"\n",
        "    i7=\"${output_dir}/step_1/ERA5_${year}_7.grib\"\n",
        "    i8=\"${output_dir}/step_1/ERA5_${year}_8.grib\"\n",
        "    i9=\"${output_dir}/step_1/ERA5_${year}_9.grib\"\n",
        "    i10=\"${output_dir}/step_1/ERA5_${year}_10.grib\"\n",
        "    i11=\"${output_dir}/step_1/ERA5_${year}_11.grib\"\n",
        "    i12=\"${output_dir}/step_1/ERA5_${year}_12.grib\"\n",
        "\n",
        "    o_t_dew=\"${output_dir}/step_2/ERA5_for_gapfill/dew_ERA5_${year}.nc\"\n",
        "    o_tas=\"${output_dir}/step_2/ERA5_for_gapfill/tas_ERA5_${year}.nc\"\n",
        "    o_tasmin=\"${output_dir}/step_2/ERA5_for_gapfill/tasmin_ERA5_${year}.nc\"\n",
        "    o_tasmax=\"${output_dir}/step_2/ERA5_for_gapfill/tasmax_ERA5_${year}.nc\"\n",
        "    o_sfcWind=\"${output_dir}/step_2/ERA5_for_gapfill/sfcWind_ERA5_${year}.nc\"\n",
        "    o_rsds=\"${output_dir}/step_2/ERA5_for_gapfill/rsds_ERA5_${year}.nc\"\n",
        "    o_pr=\"${output_dir}/step_2/ERA5_for_gapfill/pr_ERA5_${year}.nc\"\n",
        "    o_hurs=\"${output_dir}/step_2/ERA5_for_gapfill/hurs_ERA5_${year}.nc\"\n",
        "\n",
        "\t# temperature\n",
        "    cdo -f nc expr,dpt=\"var168\" -daymean -selname,var167 -mergetime $i1 $i2 $i3 $i4 $i5 $i6 $i7 $i8 $i9 $i10 $i11 $i12 $o_tas\n",
        "    cdo -f nc expr,tx=\"var167\" -daymin -selname,var167 -mergetime $i1 $i2 $i3 $i4 $i5 $i6 $i7 $i8 $i9 $i10 $i11 $i12 $o_tasmin\n",
        "    cdo -f nc expr,tn=\"var167\" -daymax -selname,var167 -mergetime $i1 $i2 $i3 $i4 $i5 $i6 $i7 $i8 $i9 $i10 $i11 $i12 $o_tasmax\n",
        "\t# accumulations in ERA5 are hourly, different from ERA5-land    \n",
        "    cdo -f nc expr,rg=\"var169*24/86400\" -daymean -selname,var169 -mergetime $i1 $i2 $i3 $i4 $i5 $i6 $i7 $i8 $i9 $i10 $i11 $i12 $o_rsds\n",
        "    cdo -f nc expr,pr=\"var228*24/86.4\" -daymean -selname,var228 -mergetime $i1 $i2 $i3 $i4 $i5 $i6 $i7 $i8 $i9 $i10 $i11 $i12 $o_pr\n",
        "\t# convert to relative humidity    \n",
        "    cdo -f nc -daymean -selname,var168,var167 -mergetime $i1 $i2 $i3 $i4 $i5 $i6 $i7 $i8 $i9 $i10 $i11 $i12 $o_t_dew\n",
        "    cdo expr,hurs=\"(10 ^ (7.5 * (var168-273.15) / (237.3+(var168-273.15)))) / (10 ^ (7.5 * (var167-273.15) / (237.3+(var167-273.15)))) * 100\" $o_t_dew $o_hurs\n",
        "    cdo -f nc expr,ws=\"sqrt(var165*var165+var166*var166)\" -daymean -selname,var165,var166 -mergetime $i1 $i2 $i3 $i4 $i5 $i6 $i7 $i8 $i9 $i10 $i11 $i12 $o_sfcWind\n",
        "\t# remove temp files\n",
        "    rm $o_t_dew\n",
        "done\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3. EMO-1 data processing\n",
        "<a id=\"Step-3-EMO1processing\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The European Meteorological Observations (EMO) dataset is a high-resolution, gridded meteorological dataset for Europe, offering both sub-daily and daily data across multiple variables. Based on historical and real-time observations, EMO is a product of the Copernicus Emergency Management Service. The dataset includes daily totals for precipitation, minimum and maximum temperatures, wind speed, solar radiation, and water vapor pressure. Additionally, EMO provides 6-hourly data for precipitation and mean temperature. EMO-1 offers grids with a spatial resolution of 1arcminx1arcmin (approximately 1.5 km), covering the period from 1990 to 2022.\n",
        "\n",
        "To use the EMO-1 dataset for bias adjustment and downscaling with ISIMIP3BASD, it needs to be processed in the similar way as ERA5 data. First, the variables need to be processed using the script below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Download EMO-1 Data\n",
        "Script use this url https://jeodpp.jrc.ec.europa.eu/ftp/jrc-opendata/CEMS-EFAS/meteorological_forcings/EMO-1arcmin/ for downloading and saving all files in separate folders in step 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Function to get the list of files from the given URL\n",
        "def get_file_list(url):\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    \n",
        "    # Find all links leading to .nc files\n",
        "    file_links = [link.get('href') for link in soup.find_all('a') if link.get('href').endswith('.nc')]\n",
        "    return file_links\n",
        "\n",
        "# Function to download a file and save it locally\n",
        "def download_file(file_url, save_directory):\n",
        "    response = requests.get(file_url)\n",
        "    filename = os.path.join(save_directory, file_url.split('/')[-1])\n",
        "    \n",
        "    with open(filename, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "    print(f\"Downloaded: {file_url}\")\n",
        "\n",
        "# Function to iterate through specific folders and download files\n",
        "def download_files_from_specific_folders(base_url, save_directory, folders):\n",
        "    for folder in folders:\n",
        "        full_folder_url = f\"{base_url}/{folder}\"\n",
        "        print(f\"Processing folder: {full_folder_url}\")\n",
        "        \n",
        "        # Create the subdirectory if it does not exist\n",
        "        folder_save_directory = os.path.join(save_directory, folder)\n",
        "        if not os.path.exists(folder_save_directory):\n",
        "            os.makedirs(folder_save_directory)\n",
        "        \n",
        "        file_list = get_file_list(full_folder_url)\n",
        "        \n",
        "        for file_link in file_list:\n",
        "            full_file_url = f\"{full_folder_url}/{file_link}\"\n",
        "            download_file(full_file_url, folder_save_directory)\n",
        "\n",
        "# Usage\n",
        "base_url = 'https://jeodpp.jrc.ec.europa.eu/ftp/jrc-opendata/CEMS-EFAS/meteorological_forcings/EMO-1arcmin'\n",
        "save_directory = \"${output_dir}/step_3/emo_data\"\n",
        "folders = ['pr', 'rg', 'tn', 'tx', 'ws']  # List of folders to iterate through\n",
        "\n",
        "# Create the main directory to save downloaded files if it doesn't exist\n",
        "if not os.path.exists(save_directory):\n",
        "    os.makedirs(save_directory)\n",
        "\n",
        "download_files_from_specific_folders(base_url, save_directory, folders)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cut EMO-1 to same dimensions as ERA5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from netCDF4 import Dataset\n",
        "\n",
        "\"\"\"\n",
        "The script cuts the dimensions to specific latitude and longitude\n",
        "of the original EMO1 file downloaded from https://jeodpp.jrc.ec.europa.eu/ftp/jrc-opendata/\n",
        "It will loop over the folder and save each file with in a different folder to prevent any permission error\n",
        "associated with .nc files\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "ininput_dir = \"${output_dir}/step_3/emo_data\"\n",
        "output_subdir = \"${output_dir}/step_3/emo_data/cutted_emo\"\n",
        "\n",
        "lon_min, lon_max = 12.950000, 26.050000  #For Poland\n",
        "lat_min, lat_max = 47.950000, 55.050000  #For Poland\n",
        "\n",
        "chunk_size = 100\n",
        "\n",
        "def process_variable_in_chunks(src_var, dst_var, lon_indices, lat_indices):\n",
        "    full_shape = src_var.shape\n",
        "    dim_names = src_var.dimensions\n",
        "    lat_dim = dim_names.index('lat') if 'lat' in dim_names else None\n",
        "    lon_dim = dim_names.index('lon') if 'lon' in dim_names else None\n",
        "    src_slices = [slice(None)] * len(full_shape)\n",
        "    dst_slices = [slice(None)] * len(full_shape)\n",
        "    \n",
        "    if lat_dim is not None:\n",
        "        src_slices[lat_dim] = lat_indices\n",
        "        dst_slices[lat_dim] = slice(None)\n",
        "    if lon_dim is not None:\n",
        "        src_slices[lon_dim] = lon_indices\n",
        "        dst_slices[lon_dim] = slice(None)\n",
        "    if lat_dim is None and lon_dim is None:\n",
        "        dst_var[:] = src_var[:]\n",
        "        return\n",
        "\n",
        "    chunk_dims = [i for i, dim in enumerate(dim_names) if dim not in ['lat', 'lon']]\n",
        "    chunk_dim = chunk_dims[0] if chunk_dims else 0\n",
        "    \n",
        "    for start in range(0, full_shape[chunk_dim], chunk_size):\n",
        "        end = min(start + chunk_size, full_shape[chunk_dim])\n",
        "        src_chunk_slices = list(src_slices)\n",
        "        dst_chunk_slices = list(dst_slices)\n",
        "        src_chunk_slices[chunk_dim] = slice(start, end)\n",
        "        dst_chunk_slices[chunk_dim] = slice(start, end)\n",
        "        \n",
        "        chunk_data = src_var[tuple(src_chunk_slices)]\n",
        "        dst_var[tuple(dst_chunk_slices)] = chunk_data\n",
        "\n",
        "def cut_file_for_poland(input_file_path, output_file_dir):\n",
        "    try:\n",
        "        with Dataset(input_file_path, 'r') as src:\n",
        "            lon = src.variables['lon'][:]\n",
        "            lat = src.variables['lat'][:]\n",
        "            lon_indices = np.where((lon >= lon_min) & (lon <= lon_max))[0]\n",
        "            lat_indices = np.where((lat >= lat_min) & (lat <= lat_max))[0]\n",
        "            \n",
        "            output_file_name = os.path.basename(input_file_path).replace('.nc', '_poland.nc')\n",
        "            output_file_path = os.path.join(output_file_dir, output_file_name)\n",
        "            \n",
        "            with Dataset(output_file_path, 'w') as dst:\n",
        "                dst.setncatts({a: src.getncattr(a) for a in src.ncattrs()})\n",
        "                for name, dimension in src.dimensions.items():\n",
        "                    if name == 'lon':\n",
        "                        dst.createDimension(name, len(lon_indices))\n",
        "                    elif name == 'lat':\n",
        "                        dst.createDimension(name, len(lat_indices))\n",
        "                    else:\n",
        "                        dst.createDimension(name, (len(dimension) if not dimension.isunlimited() else None))\n",
        "                \n",
        "                for name, variable in src.variables.items():\n",
        "                    if name in ['lon', 'lat']:\n",
        "                        x = dst.createVariable(name, variable.datatype, (name,))\n",
        "                    else:\n",
        "                        x = dst.createVariable(name, variable.datatype, variable.dimensions)\n",
        "                    \n",
        "                    dst[name].setncatts({a: variable.getncattr(a) for a in variable.ncattrs()})\n",
        "                    \n",
        "                    if name == 'lon':\n",
        "                        dst[name][:] = lon[lon_indices]\n",
        "                    elif name == 'lat':\n",
        "                        dst[name][:] = lat[lat_indices]\n",
        "                    else:\n",
        "                        process_variable_in_chunks(src[name], dst[name], lon_indices, lat_indices)\n",
        "\n",
        "        print(f\"Successfully created cut file: {output_file_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to process file {input_file_path}. Error: {e}\")\n",
        "        raise\n",
        "\n",
        "def process_folder(folder_path):\n",
        "    try:\n",
        "        output_subfolder = os.path.join(output_subdir, f\"Cutted_{os.path.basename(folder_path)}\")\n",
        "        if not os.path.exists(output_subfolder):\n",
        "            os.makedirs(output_subfolder)\n",
        "        \n",
        "        for file_name in os.listdir(folder_path):\n",
        "            if file_name.endswith(\".nc\"):\n",
        "                file_path = os.path.join(folder_path, file_name)\n",
        "                \n",
        "                print(f\"Processing file: {file_path}\")\n",
        "                cut_file_for_poland(file_path, output_subfolder)\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing folder {folder_path}. Error: {e}\")\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        if not os.path.exists(output_subdir):\n",
        "            os.makedirs(output_subdir)\n",
        "        \n",
        "        subfolders = ['pd', 'pr', 'ws', 'rg', 'tn', 'tx']\n",
        "        \n",
        "        for subfolder in subfolders:\n",
        "            folder_path = os.path.join(input_dir, subfolder)\n",
        "            if os.path.isdir(folder_path):\n",
        "                print(f\"Processing folder: {folder_path}\")\n",
        "                process_folder(folder_path)\n",
        "            else:\n",
        "                print(f\"Folder not found: {folder_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Critical error in main processing loop. Error: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "for y in {1990..2022}\n",
        "do\n",
        "\tyear=\"$y\"\n",
        "\n",
        "\ttx=\"${output_dir}/step_3/emo_data/cutted_emo/tx/EMO-1arcmin-tx_${year}.nc\"\n",
        "\ttn=\"${output_dir}/step_3/emo_data/cutted_emo/tn/EMO-1arcmin-tn_${year}.nc\"\n",
        "\ttasmax=\"${output_dir}/step_3/emo_data/EFAS_converted/tasmax_${year}.nc\"\n",
        "\ttasmin=\"${output_dir}/step_3/emo_data/EFAS_converted/tasmin_${year}.nc\"\n",
        "    tas=\"${output_dir}/step_3/emo_data/EFAS_converted/tas_${year}.nc\"\n",
        "\n",
        "\tcdo -f nc4c -z zip expr,tasmax=\"tx + 273.15\" $tx $tasmax\n",
        "\tcdo -f nc4c -z zip expr,tasmin=\"tn + 273.15\" $tn $tasmin\n",
        "\tcdo -f nc4c -z zip expr,tas=\"(tx + tn) / 2 + 273.15\" -merge $tx $tn $tas\n",
        "\n",
        "\thurs0=\"${output_dir}/step_3/emo_data/EFAS_converted/hurs_raw_${year}.nc\"\n",
        "\thurs=\"${output_dir}/step_3/emo_data/EFAS_converted/hurs_${year}.nc\"\n",
        "\tpd=\"${output_dir}/step_3/emo_data/cutted_emo/pd/pd_${year}.nc\"\n",
        "\n",
        "\tcdo -f nc4c -z zip -expr,hurs=\"pd / (6.11 * 10 ^ (7.5 * ((tn+tx)/2) / (237.3+((tn+tx)/2) ) )) * 100\" -merge $tn $tx -shifttime,-1days $pd $hurs0\n",
        "\tcdo -f nc4c -z zip -expr,hurs=\"(hurs > 100 ) ? 100 : hurs\" $hurs0 $hurs\n",
        "\n",
        "\tws=\"${output_dir}/step_3/emo_data/cutted_emo/ws/ws_${year}.nc\"\n",
        "\tsfcWind=\"${output_dir}/step_3/emo_data/EFAS_converted/sfcWind_${year}.nc\"\n",
        "\n",
        "\tcdo -f nc4c -z zip expr,sfcWind=\"ws\" -shifttime,-1days $ws $sfcWind\n",
        "\n",
        "\tpr=\"${output_dir}/step_3/emo_data/cutted_emo/pr/pr_${year}.nc\"\n",
        "\tpr_c=\"${output_dir}/step_3/emo_data/EFAS_converted/pr_${year}.nc\"\n",
        "\n",
        "\tcdo -f nc4c -z zip expr,pr=\"pr/86400\" -shifttime,-1days $pr $pr_c\n",
        "\n",
        "\trg=\"${output_dir}/step_3/emo_data/cutted_emo/rg/rg_${year}.nc\"\n",
        "\trsds=\"${output_dir}/step_3/emo_data/EFAS_converted/rsds_${year}.nc\"\n",
        "\n",
        "\tcdo -f nc4c -z zip expr,rsds=\"rg/86400\" -shifttime,-1days $rg $rsds\n",
        "\n",
        "done"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The scripts performs the following actions:\n",
        "\n",
        "1. **Temperature Conversion:**\n",
        "Converts maximum (`tx`) and minimum (`tn`) temperatures from Celsius to Kelvin by adding 273.15.\n",
        "Calculates mean temperature (`tas`) as the average of `tx` and `tn`, then converts to Kelvin.\n",
        "\n",
        "2. **Relative Humidity Calculation:**\n",
        "Computes relative humidity (`hurs`) using temperature and partial pressure data.\n",
        "The calculation uses the Magnus formula for saturation vapor pressure.\n",
        "Limits the relative humidity to a maximum of 100%.\n",
        "\n",
        "3. **Wind Speed Conversion:**\n",
        "Converts wind speed (`ws`) to surface wind (`sfcWind`) without changing values.\n",
        "\n",
        "4. **Precipitation Rate Conversion:**\n",
        "Converts precipitation (`pr`) from mm/day to mm/second by dividing by 86400 (seconds in a day).\n",
        "\n",
        "5. **Solar Radiation Conversion:**\n",
        "Converts global radiation (`rg`) to downward short-wave radiation flux (`rsds`) by dividing by 86400.\n",
        "\n",
        "6. **Time Adjustment:**\n",
        "Applies a one-day backward time shift to certain variables (`hurs`, `sfcWind`, `pr`, `rsds`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4. Data merging\n",
        "<a id=\"Step-4-merging\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, the data has been pre-processed for ERA5-Land and EMO-1. Subsequently, the data will now be merged as merging of these files allows for easier handling of long-term climate data series, which is crucial for ease in running simulations in later stages of the process.\n",
        "\n",
        "For this purpose, the script below is designed to consolidate climate data from different sources and time periods. It creates three merged files: two for ERA5-Land data (covering 1950-1989 and 1990-2022) and one for EMO-1 data (covering 1990-2022)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "# Define the base directory for the output as a variable\n",
        "STEP_4_OUTPUT=\"${output_dir}/step_4\"\n",
        "MERGE_ERA5=\"${STEP_4_OUTPUT}/merge_era5\"\n",
        "MERGE_EMO1=\"${STEP_4_OUTPUT}/merge_emo1\"\n",
        "\n",
        "# Create the output directories if they don't exist\n",
        "mkdir -p $MERGE_ERA5\n",
        "mkdir -p $MERGE_EMO1\n",
        "\n",
        "## Merge files per variable for ERA5_Land; convert the script to cover all vars: tas, tasmin, tasmax, sfcWind, hurs, rsds, pr\n",
        "\n",
        "## Merge ERA5_Land for the period which is available in EMO-1, i.e. 1990-2022\n",
        "cdo mergetime ${output_dir}/step_2/ERA5_land_daily/hurs_ERA5_199?.nc ${output_dir}/step_2/ERA5_land_daily/hurs_ERA5_200?.nc ${output_dir}/step_2/ERA5_land_daily/hurs_ERA5_201?.nc ${output_dir}/step_2/ERA5_land_daily/hurs_ERA5_2020.nc ${output_dir}/step_2/ERA5_land_daily/hurs_ERA5_2021.nc ${output_dir}/step_2/ERA5_land_daily/hurs_ERA5_2022.nc $MERGE_ERA5/hurs_ERA5_1990_2022_t.nc\n",
        "cdo mergetime ${output_dir}/step_2/ERA5_land_daily/tas_ERA5_199?.nc ${output_dir}/step_2/ERA5_land_daily/tas_ERA5_200?.nc ${output_dir}/step_2/ERA5_land_daily/tas_ERA5_201?.nc ${output_dir}/step_2/ERA5_land_daily/tas_ERA5_2020.nc ${output_dir}/step_2/ERA5_land_daily/tas_ERA5_2021.nc ${output_dir}/step_2/ERA5_land_daily/tas_ERA5_2022.nc $MERGE_ERA5/tas_ERA5_1990_2022_t.nc\n",
        "cdo mergetime ${output_dir}/step_2/ERA5_land_daily/tasmin_ERA5_199?.nc ${output_dir}/step_2/ERA5_land_daily/tasmin_ERA5_200?.nc ${output_dir}/step_2/ERA5_land_daily/tasmin_ERA5_201?.nc ${output_dir}/step_2/ERA5_land_daily/tasmin_ERA5_2020.nc ${output_dir}/step_2/ERA5_land_daily/tasmin_ERA5_2021.nc ${output_dir}/step_2/ERA5_land_daily/tasmin_ERA5_2022.nc $MERGE_ERA5/tasmin_ERA5_1990_2022_t.nc\n",
        "cdo mergetime ${output_dir}/step_2/ERA5_land_daily/tasmax_ERA5_199?.nc ${output_dir}/step_2/ERA5_land_daily/tasmax_ERA5_200?.nc ${output_dir}/step_2/ERA5_land_daily/tasmax_ERA5_201?.nc ${output_dir}/step_2/ERA5_land_daily/tasmax_ERA5_2020.nc ${output_dir}/step_2/ERA5_land_daily/tasmax_ERA5_2021.nc ${output_dir}/step_2/ERA5_land_daily/tasmax_ERA5_2022.nc $MERGE_ERA5/tasmax_ERA5_1990_2022_t.nc\n",
        "cdo mergetime ${output_dir}/step_2/ERA5_land_daily/sfcWind_ERA5_199?.nc ${output_dir}/step_2/ERA5_land_daily/sfcWind_ERA5_200?.nc ${output_dir}/step_2/ERA5_land_daily/sfcWind_ERA5_201?.nc ${output_dir}/step_2/ERA5_land_daily/sfcWind_ERA5_2020.nc ${output_dir}/step_2/ERA5_land_daily/sfcWind_ERA5_2021.nc ${output_dir}/step_2/ERA5_land_daily/sfcWind_ERA5_2022.nc $MERGE_ERA5/sfcWind_ERA5_1990_2022_t.nc\n",
        "cdo mergetime ${output_dir}/step_2/ERA5_land_daily/rsds_ERA5_199?.nc ${output_dir}/step_2/ERA5_land_daily/rsds_ERA5_200?.nc ${output_dir}/step_2/ERA5_land_daily/rsds_ERA5_201?.nc ${output_dir}/step_2/ERA5_land_daily/rsds_ERA5_2020.nc ${output_dir}/step_2/ERA5_land_daily/rsds_ERA5_2021.nc ${output_dir}/step_2/ERA5_land_daily/rsds_ERA5_2022.nc $MERGE_ERA5/rsds_ERA5_1990_2022_t.nc\n",
        "cdo mergetime ${output_dir}/step_2/ERA5_land_daily/pr_ERA5_199?.nc ${output_dir}/step_2/ERA5_land_daily/pr_ERA5_200?.nc ${output_dir}/step_2/ERA5_land_daily/pr_ERA5_201?.nc ${output_dir}/step_2/ERA5_land_daily/pr_ERA5_2020.nc ${output_dir}/step_2/ERA5_land_daily/pr_ERA5_2021.nc ${output_dir}/step_2/ERA5_land_daily/pr_ERA5_2022.nc $MERGE_ERA5/pr_ERA5_1990_2022_t.nc\n",
        "\n",
        "## Merge ERA5_Land for the preceding period which is NOT available in EMO-1, i.e. 1950-1989\n",
        "cdo mergetime ${output_dir}/step_2/ERA5_land_daily/hurs_ERA5_195?.nc ${output_dir}/step_2/ERA5_land_daily/hurs_ERA5_196?.nc ${output_dir}/step_2/ERA5_land_daily/hurs_ERA5_197?.nc ${output_dir}/step_2/ERA5_land_daily/hurs_ERA5_198?.nc $MERGE_ERA5/hurs_ERA5_1950_1989_t.nc\n",
        "cdo mergetime ${output_dir}/step_2/ERA5_land_daily/tas_ERA5_195?.nc ${output_dir}/step_2/ERA5_land_daily/tas_ERA5_196?.nc ${output_dir}/step_2/ERA5_land_daily/tas_ERA5_197?.nc ${output_dir}/step_2/ERA5_land_daily/tas_ERA5_198?.nc $MERGE_ERA5/tas_ERA5_1950_1989_t.nc\n",
        "cdo mergetime ${output_dir}/step_2/ERA5_land_daily/tasmin_ERA5_195?.nc ${output_dir}/step_2/ERA5_land_daily/tasmin_ERA5_196?.nc ${output_dir}/step_2/ERA5_land_daily/tasmin_ERA5_197?.nc ${output_dir}/step_2/ERA5_land_daily/tasmin_ERA5_198?.nc $MERGE_ERA5/tasmin_ERA5_1950_1989_t.nc\n",
        "cdo mergetime ${output_dir}/step_2/ERA5_land_daily/tasmax_ERA5_195?.nc ${output_dir}/step_2/ERA5_land_daily/tasmax_ERA5_196?.nc ${output_dir}/step_2/ERA5_land_daily/tasmax_ERA5_197?.nc ${output_dir}/step_2/ERA5_land_daily/tasmax_ERA5_198?.nc $MERGE_ERA5/tasmax_ERA5_1950_1989_t.nc\n",
        "cdo mergetime ${output_dir}/step_2/ERA5_land_daily/sfcWind_ERA5_195?.nc ${output_dir}/step_2/ERA5_land_daily/sfcWind_ERA5_196?.nc ${output_dir}/step_2/ERA5_land_daily/sfcWind_ERA5_197?.nc ${output_dir}/step_2/ERA5_land_daily/sfcWind_ERA5_198?.nc $MERGE_ERA5/sfcWind_ERA5_1950_1989_t.nc\n",
        "cdo mergetime ${output_dir}/step_2/ERA5_land_daily/rsds_ERA5_195?.nc ${output_dir}/step_2/ERA5_land_daily/rsds_ERA5_196?.nc ${output_dir}/step_2/ERA5_land_daily/rsds_ERA5_197?.nc ${output_dir}/step_2/ERA5_land_daily/rsds_ERA5_198?.nc $MERGE_ERA5/rsds_ERA5_1950_1989_t.nc\n",
        "cdo mergetime ${output_dir}/step_2/ERA5_land_daily/pr_ERA5_195?.nc ${output_dir}/step_2/ERA5_land_daily/pr_ERA5_196?.nc ${output_dir}/step_2/ERA5_land_daily/pr_ERA5_197?.nc ${output_dir}/step_2/ERA5_land_daily/pr_ERA5_198?.nc $MERGE_ERA5/pr_ERA5_1950_1989_t.nc\n",
        "\n",
        "## Merge EMO-1 files using relative paths\n",
        "cdo -f nc4c -z zip mergetime ${output_dir}/step_3/emo_data/EFAS_converted/hurs_199?.nc ${output_dir}/step_3/emo_data/EFAS_converted/hurs_200?.nc ${output_dir}/step_3/emo_data/EFAS_converted/hurs_201?.nc ${output_dir}/step_3/emo_data/EFAS_converted/hurs_2020.nc ${output_dir}/step_3/emo_data/EFAS_converted/hurs_2021.nc ${output_dir}/step_3/emo_data/EFAS_converted/hurs_2022.nc $MERGE_EMO1/hurs_1990_2022_t.nc\n",
        "cdo -f nc4c -z zip mergetime ${output_dir}/step_3/emo_data/EFAS_converted/tas_199?.nc ${output_dir}/step_3/emo_data/EFAS_converted/tas_200?.nc ${output_dir}/step_3/emo_data/EFAS_converted/tas_201?.nc ${output_dir}/step_3/emo_data/EFAS_converted/tas_2020.nc ${output_dir}/step_3/emo_data/EFAS_converted/tas_2021.nc ${output_dir}/step_3/emo_data/EFAS_converted/tas_2022.nc $MERGE_EMO1/tas_1990_2022_t.nc\n",
        "cdo -f nc4c -z zip mergetime ${output_dir}/step_3/emo_data/EFAS_converted/tasmin_199?.nc ${output_dir}/step_3/emo_data/EFAS_converted/tasmin_200?.nc ${output_dir}/step_3/emo_data/EFAS_converted/tasmin_201?.nc ${output_dir}/step_3/emo_data/EFAS_converted/tasmin_2020.nc ${output_dir}/step_3/emo_data/EFAS_converted/tasmin_2021.nc ${output_dir}/step_3/emo_data/EFAS_converted/tasmin_2022.nc $MERGE_EMO1/tasmin_1990_2022_t.nc\n",
        "cdo -f nc4c -z zip mergetime ${output_dir}/step_3/emo_data/EFAS_converted/tasmax_199?.nc ${output_dir}/step_3/emo_data/EFAS_converted/tasmax_200?.nc ${output_dir}/step_3/emo_data/EFAS_converted/tasmax_201?.nc ${output_dir}/step_3/emo_data/EFAS_converted/tasmax_2020.nc ${output_dir}/step_3/emo_data/EFAS_converted/tasmax_2021.nc ${output_dir}/step_3/emo_data/EFAS_converted/tasmax_2022.nc $MERGE_EMO1/tasmax_1990_2022_t.nc\n",
        "cdo -f nc4c -z zip mergetime ${output_dir}/step_3/emo_data/EFAS_converted/sfcWind_199?.nc ${output_dir}/step_3/emo_data/EFAS_converted/sfcWind_200?.nc ${output_dir}/step_3/emo_data/EFAS_converted/sfcWind_201?.nc ${output_dir}/step_3/emo_data/EFAS_converted/sfcWind_2020.nc ${output_dir}/step_3/emo_data/EFAS_converted/sfcWind_2021.nc ${output_dir}/step_3/emo_data/EFAS_converted/sfcWind_2022.nc $MERGE_EMO1/sfcWind_1990_2022_t.nc\n",
        "cdo -f nc4c -z zip mergetime ${output_dir}/step_3/emo_data/EFAS_converted/rsds_199?.nc ${output_dir}/step_3/emo_data/EFAS_converted/rsds_200?.nc ${output_dir}/step_3/emo_data/EFAS_converted/rsds_201?.nc ${output_dir}/step_3/emo_data/EFAS_converted/rsds_2020.nc ${output_dir}/step_3/emo_data/EFAS_converted/rsds_2021.nc ${output_dir}/step_3/emo_data/EFAS_converted/rsds_2022.nc $MERGE_EMO1/rsds_1990_2022_t.nc\n",
        "cdo -f nc4c -z zip mergetime ${output_dir}/step_3/emo_data/EFAS_converted/pr_199?.nc ${output_dir}/step_3/emo_data/EFAS_converted/pr_200?.nc ${output_dir}/step_3/emo_data/EFAS_converted/pr_201?.nc ${output_dir}/step_3/emo_data/EFAS_converted/pr_2020.nc ${output_dir}/step_3/emo_data/EFAS_converted/pr_2021.nc ${output_dir}/step_3/emo_data/EFAS_converted/pr_2022.nc $MERGE_EMO1/pr_1990_2022_t.nc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. **ERA5-Land Data Merging (1990-2022)**:\n",
        "\n",
        "Merges ERA5-Land relative humidity data files for the years 1990 to 2022.\n",
        "Uses wildcard patterns (e.g., '199?.nc') to include all files for each decade.\n",
        "The merged output is saved as, e.g: 'hurs_ERA5_1990_2022_t.nc'.\n",
        "\n",
        "2. **ERA5-Land Data Merging (1950-1989)**:\n",
        "\n",
        "Merges ERA5-Land relative humidity data files for the years 1950 to 1989.\n",
        "This covers the period not available in EMO-1 dataset.\n",
        "The merged output is saved as, e.g: 'hurs_ERA5_1950_1989_t.nc'.\n",
        "\n",
        "3. **EMO-1 Data Merging (1990-2022)**:\n",
        "\n",
        "Merges EMO-1 relative humidity data files for the years 1990 to 2022.\n",
        "Uses the CDO (Climate Data Operators) tool with specific options:\n",
        "\n",
        "'-f nc4c': Specifies NetCDF4 classic format output.\n",
        "'-z zip': Applies zip compression to the output file.\n",
        "The merged output is saved as, e.g: 'hurs_1990_2022_t.nc'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5. Processing of combined ERA5-Land for bias-adjustment\n",
        "<a id=\"Step-5-secondary-processing\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The combined ERA5-Land data from step 4 for the year (1950-1989) and (1990-2022) will go through set of procedures to ensure that the dimensions of each file are in-accordance with the requirements of ISIMIP3BASD scripts. For this purpose, the below script will reorder the dimensions of the NetCDF file to lon,lat,time from time,lat,lon.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "# number of netCDF chunks (do not change)\n",
        "n_lats=10\n",
        "n_lons=10\n",
        "\n",
        "#Processes each variable seperately to add a second time period for bias_adjustment\n",
        "#hurs\n",
        "filename=\"${output_dir}/step_4/merge_era5/ERA5_land_daily/hurs_ERA5_1950_1989_t.nc\"  #for merged data\n",
        "#filename=\"${output_dir}/step_2/ERA5_land_daily/hurs_ERA5_2023.nc\"  #for selected year \n",
        "\n",
        "filename=\"${output_dir}/step_4/merge_era5/ERA5_land_daily/hurs_ERA5_1950_1989_t.nc\"\n",
        "n_times=$(cdo ntime $filename)\n",
        "ncpdq -4 -O --cnk_plc=g3d --cnk_dmn=time,$n_times --cnk_dmn=lat,$n_lats --cnk_dmn=lon,$n_lons -a lon,lat,time $filename \"${output_dir}/step_5/ERA5_$(basename \"$filename\" .nc).nc\"\n",
        "\n",
        "#tas\n",
        "##### After generate file remember to rename variable name to tas, same as EMO1\n",
        "##### use this code in terminal: ncrename -v 2t,tas /mnt/g/compass/compass_framework/step_5/tas_YEAR.nc #replace input file with the tas file that you want to rename\n",
        "filename2=\"${output_dir}/step_4/merge_era5/ERA5_land_daily/tas_ERA5_1950_1989_t.nc\"\n",
        "n_times=$(cdo ntime $filename2)\n",
        "ncpdq -4 -O --cnk_plc=g3d --cnk_dmn=time,$n_times --cnk_dmn=lat,$n_lats --cnk_dmn=lon,$n_lons -a lon,lat,time $filename2 \"${output_dir}/step_5/ERA5_$(basename \"$filename2\" .nc).nc\"\n",
        "#\n",
        "echo \"n_times: $n_times\"\n",
        "echo \"n_lats: $n_lats\"\n",
        "echo \"n_lons: $n_lons\"\n",
        "echo \"Filename: $filename2\"\n",
        "echo \"Output file: ${output_dir}/step_5/ERA5_$(basename \"$filename2\" .nc)\"\n",
        "\n",
        "#sfcWind\n",
        "filename3=\"${output_dir}/step_4/merge_era5/ERA5_land_daily/sfcWind_ERA5_1950_1989_t.nc\"\n",
        "n_times=$(cdo ntime $filename3)\n",
        "ncpdq -4 -O --cnk_plc=g3d --cnk_dmn=time,$n_times --cnk_dmn=lat,$n_lats --cnk_dmn=lon,$n_lons -a lon,lat,time $filename3 \"${output_dir}/step_5/ERA5_$(basename \"$filename3\" .nc).nc\"\n",
        "#\n",
        "echo \"n_times: $n_times\"\n",
        "echo \"n_lats: $n_lats\"\n",
        "echo \"n_lons: $n_lons\"\n",
        "echo \"Filename: $filename3\"\n",
        "echo \"Output file: ${output_dir}/step_5/ERA5_$(basename \"$filename3\" .nc)\"\n",
        "\n",
        "#rsds\n",
        "filename4=\"${output_dir}/step_4/merge_era5/ERA5_land_daily/rsds_ERA5_1950_1989_t.nc\"\n",
        "n_times=$(cdo ntime $filename4)\n",
        "ncpdq -4 -O --cnk_plc=g3d --cnk_dmn=time,$n_times --cnk_dmn=lat,$n_lats --cnk_dmn=lon,$n_lons -a lon,lat,time $filename4 \"${output_dir}/step_5/ERA5_$(basename \"$filename4\" .nc).nc\"\n",
        "#\n",
        "echo \"n_times: $n_times\"\n",
        "echo \"n_lats: $n_lats\"\n",
        "echo \"n_lons: $n_lons\"\n",
        "echo \"Filename: $filename4\"\n",
        "echo \"Output file: ${output_dir}/step_5/ERA5_$(basename \"$filename4\" .nc)\"\n",
        "\n",
        "#pr\n",
        "filename5=\"${output_dir}/step_4/merge_era5/ERA5_land_daily/pr_ERA5_1950_1989_t.nc\"\n",
        "n_times=$(cdo ntime $filename5)\n",
        "ncpdq -4 -O --cnk_plc=g3d --cnk_dmn=time,$n_times --cnk_dmn=lat,$n_lats --cnk_dmn=lon,$n_lons -a lon,lat,time $filename5 \"${output_dir}/step_5/ERA5_$(basename \"$filename5\" .nc).nc\"\n",
        "#\n",
        "echo \"n_times: $n_times\"\n",
        "echo \"n_lats: $n_lats\"\n",
        "echo \"n_lons: $n_lons\"\n",
        "echo \"Filename: $filename5\"\n",
        "echo \"Output file: ${output_dir}/step_5/ERA5_$(basename \"$filename5\" .nc)\"\n",
        "\n",
        "#Convert tas to tasrange and tasskew\n",
        "tas=\"${output_dir}/step_4/merge_era5/ERA5_land_daily/tas_ERA5_1950_1989_t.nc\"\n",
        "tn=\"${output_dir}/step_4/merge_era5/ERA5_land_daily/tasmin_ERA5_1950_1989_t.nc\"\n",
        "tx=\"${output_dir}/step_4/merge_era5/ERA5_land_daily/tasmax_ERA5_1950_1989_t.nc\"\n",
        "tasrange=\"${output_dir}/step_4/merge_era5/ERA5_land_daily/tasrange_ERA5_1950_1989_t.nc\"\n",
        "tasskew=\"${output_dir}/step_4/merge_era5/ERA5_land_daily/tasskew_ERA5_1950_1989_t.nc\"\n",
        "n_times=$(cdo ntime $tas)\n",
        "##\n",
        "cdo expr,tasrange=\"tx - tn\" -merge -chname,var167,tn $tn -chname,var167,tx $tx $tasrange\n",
        "cdo expr,tasskew=\" ( tas - tn ) / ( tx - tn ) \" -merge -chname,var167,tn $tn -chname,var167,tx $tx -chname,var167,tas $tas $tasskew\n",
        "##\n",
        "ncpdq -4 -O --cnk_plc=g3d --cnk_dmn=time,$n_times --cnk_dmn=lat,$n_lats --cnk_dmn=lon,$n_lons -a lon,lat,time $tasrange \"${output_dir}/step_5/ERA5_$(basename \"$tasrange\" .nc).nc\"\n",
        "ncpdq -4 -O --cnk_plc=g3d --cnk_dmn=time,$n_times --cnk_dmn=lat,$n_lats --cnk_dmn=lon,$n_lons -a lon,lat,time $tasskew \"${output_dir}/step_5/ERA5_$(basename \"$tasskew\" .nc).nc\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The script also generates new variables for the temperature calculations (`tasrange` & `tasskew`):\n",
        "\n",
        "a. `tasrange`: Difference between maximum and minimum temperatures.\n",
        "\n",
        "b. `tasskew`: Normalized temperature, indicating where the mean temperature falls between the daily minimum and maximum."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6. Processing of combined EMO-1 data\n",
        "<a id=\"Step-6-secondary-processing-emo-1\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The combined EMO-1 data from step 4 will be scaled to the same resolution as ERA5-Land to ensure consistency in bias_adjustment and downscaling procedure. The procedure involves generating a grid file with of ERA5Land and remapping the generated weight file from EMO-1 file based on the grid_file. Finally, an aggregated file is generated which is remapped based on the grid_file from ERA5-Land ensuring similar resolution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "## convert high-res EMO-1 files into the same resolution as ERA5Land;\n",
        "\n",
        "# ERA5Land file to generate grid file\n",
        "# the grid file will be the same across all ERA5 land files (for given time period), just generate once\n",
        "\n",
        "## List of variables to process\n",
        "variables=(\"tas\" \"pr\" \"rsds\" \"sfcWind\" \"tasmax\" \"tasmin\" \"hurs\")\n",
        "\n",
        "## Loop to process each variable\n",
        "for var in \"${variables[@]}\"; do\n",
        "    # ERA5Land file to generate grid file\n",
        "    era5_name=\"${output_dir}/step_4/merge_era5/${var}_ERA5_2023.nc\"  #file from step 4 or if it is only one year from step 2\n",
        "    grid_file=\"${output_dir}/step_4/merge_era5/${var}_ERA5_1990_2022_t_aggregate.txt\"\n",
        "    cdo griddes $era5_name > $grid_file\n",
        "\n",
        "    # Generate conservative remapping weights\n",
        "    emo1_file=\"${output_dir}/step_4/merge_emo1/${var}_1990_2022_t.nc\"\n",
        "    weight_file=\"${output_dir}/step_4/merge_emo1/remap_weight_${var}_1990_2022_t_aggregate.nc\"\n",
        "    efas_grid=\"${output_dir}/step_4/merge_emo1/efas_grid.txt\"\n",
        "    cdo gencon,$grid_file -setgrid,$efas_grid $emo1_file $weight_file\n",
        "\n",
        "    # Remap EMO1 file\n",
        "    cdo remap,$grid_file,$weight_file $emo1_file \"${output_dir}/step_6/${var}_1990_2022_t_aggregate.nc\"\n",
        "done\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7. Processing of combined EMO-1 data for bias adjustment\n",
        "<a id=\"Step-7-secondary-processing-emo-1-ba\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Repeating the bias adjustment processing procedure as described in step 5 for EMO-1 data now. Running the script below will convert the dimensions of EMO-1 data to proper format ready for bias adjustment and downscaling.\n",
        "\n",
        "### Use only for merged data (for example 1990-2022)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "# Number of netCDF chunks (do not change)\n",
        "n_lats=10\n",
        "n_lons=10\n",
        "\n",
        "# List of variables to process\n",
        "variables=(\"tas\" \"sfcWind\" \"hurs\" \"rsds\" \"pr\")\n",
        "types=(\"aggregate\" \"\")  # 'aggregate' and the second type is empty\n",
        "\n",
        "# Processing files for each variable and data type\n",
        "for type in \"${types[@]}\"; do\n",
        "    for var in \"${variables[@]}\"; do\n",
        "        if [ -n \"$type\" ]; then\n",
        "            filename=\"${output_dir}/step_6/${var}_1990_2022_t_${type}.nc\"\n",
        "        else\n",
        "            filename=\"${output_dir}/step_4/${var}_1990_2022_t.nc\"\n",
        "        fi\n",
        "        \n",
        "        if [ -f \"$filename\" ]; then  # Check if the file exists\n",
        "            n_times=$(cdo ntime \"$filename\" | awk 'NR==1 {print $1}')\n",
        "            ncpdq -4 -O --cnk_plc=g3d --cnk_dmn=time,$n_times --cnk_dmn=lat,$n_lats --cnk_dmn=lon,$n_lons -a lon,lat,time $filename \"${output_dir}/step_7/EFAS_$(basename \"$filename\" .nc).nc\"\n",
        "        else\n",
        "            echo \"File $filename does not exist, skipping...\"\n",
        "        fi\n",
        "    done\n",
        "done\n",
        "\n",
        "# Processing tasmin and tasmax files to tasrange and tasskew for both data types\n",
        "for type in \"${types[@]}\"; do\n",
        "    if [ -n \"$type\" ]; then\n",
        "        tas=\"${output_dir}/step_6/tas_1990_2022_t_${type}.nc\"\n",
        "        tn=\"${output_dir}/step_6/tasmin_1990_2022_t_${type}.nc\"\n",
        "        tx=\"${output_dir}/step_6/tasmax_1990_2022_t_${type}.nc\"\n",
        "        tasrange=\"${output_dir}/step_6/tasrange_1990_2022_t_${type}.nc\"\n",
        "        tasskew=\"${output_dir}/step_6/tasskew_1990_2022_t_${type}.nc\"\n",
        "    else\n",
        "        tas=\"${output_dir}/step_4/tas_1990_2022_t.nc\"\n",
        "        tn=\"${output_dir}/step_4/tasmin_1990_2022_t.nc\"\n",
        "        tx=\"${output_dir}/step_4/tasmax_1990_2022_t.nc\"\n",
        "        tasrange=\"${output_dir}/step_4/tasrange_1990_2022_t.nc\"\n",
        "        tasskew=\"${output_dir}/step_4/tasskew_1990_2022_t.nc\"\n",
        "    fi\n",
        "\n",
        "    if [ -f \"$tn\" ] && [ -f \"$tx\" ]; then\n",
        "        cdo -expr,tasrange=\"(( tasmax - tasmin ) > 0 ) ? ( tasmax - tasmin ) : ( tasmin - tasmax )\" -merge $tn $tx $tasrange\n",
        "        cdo -expr,tasskew=\" ( tas - tasmin ) / ( tasmax - tasmin ) \" -merge $tn $tx $tas $tasskew\n",
        "\n",
        "        # Processing tasrange and tasskew files\n",
        "        for file in \"$tasrange\" \"$tasskew\"; do\n",
        "            n_times=$(cdo ntime \"$filename\" | awk 'NR==1 {print $1}')\n",
        "            ncpdq -4 -O --cnk_plc=g3d --cnk_dmn=time,$n_times --cnk_dmn=lat,$n_lats --cnk_dmn=lon,$n_lons -a lon,lat,time $file \"${output_dir}/step_7/EFAS_$(basename \"$file\" .nc).nc\"\n",
        "        done\n",
        "    else\n",
        "        echo \"Files $tn or $tx do not exist, skipping...\"\n",
        "    fi\n",
        "done\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### For single-year data workflow (for example 1990 only)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "# Number of netCDF chunks (do not change)\n",
        "n_lats=10\n",
        "n_lons=10\n",
        "\n",
        "# List of variables to process\n",
        "variables=(\"tas\" \"sfcWind\" \"hurs\" \"rsds\" \"pr\")\n",
        "types=(\"aggregate\" \"\")  # 'aggregate' and the second type is empty\n",
        "\n",
        "# Processing files for each variable and data type\n",
        "for type in \"${types[@]}\"; do\n",
        "    for var in \"${variables[@]}\"; do\n",
        "        if [ -n \"$type\" ]; then\n",
        "            filename=\"${output_dir}/step_6/${var}_1990_${type}.nc\"\n",
        "        else\n",
        "            filename=\"${output_dir}/step_3/emo_data/EFAS_converted/${var}_1990.nc\"\n",
        "        fi\n",
        "        \n",
        "        if [ -f \"$filename\" ]; then  # Check if the file exists\n",
        "            n_times=$(cdo ntime \"$filename\" | awk 'NR==1 {print $1}')\n",
        "            ncpdq -4 -O --cnk_plc=g3d --cnk_dmn=time,$n_times --cnk_dmn=lat,$n_lats --cnk_dmn=lon,$n_lons -a lon,lat,time $filename \"${output_dir}/step_7/EFAS_$(basename \"$filename\" .nc).nc\"\n",
        "        else\n",
        "            echo \"File $filename does not exist, skipping...\"\n",
        "        fi\n",
        "    done\n",
        "done\n",
        "\n",
        "\n",
        "# Processing tasmin and tasmax files to tasrange and tasskew for both data types\n",
        "for type in \"${types[@]}\"; do\n",
        "    if [ -n \"$type\" ]; then\n",
        "        tas=\"${output_dir}/step_6/tas_1990_${type}.nc\"\n",
        "        tn=\"${output_dir}/step_6/tasmin_1990_${type}.nc\"\n",
        "        tx=\"${output_dir}/step_6/tasmax_1990_${type}.nc\"\n",
        "        tasrange=\"${output_dir}/step_6/tasrange_1990_${type}.nc\"\n",
        "        tasskew=\"${output_dir}/step_6/tasskew_1990_${type}.nc\"\n",
        "    else\n",
        "        tas=\"${output_dir}/step_3/emo_data/EFAS_converted/tas_1990.nc\"\n",
        "        tn=\"${output_dir}/step_3/emo_data/EFAS_converted/tasmin_1990.nc\"\n",
        "        tx=\"${output_dir}/step_3/emo_data/EFAS_converted/tasmax_1990.nc\"\n",
        "        tasrange=\"${output_dir}/step_3/emo_data/EFAS_converted/tasrange_1990.nc\"\n",
        "        tasskew=\"${output_dir}/step_3/emo_data/EFAS_converted/tasskew_1990.nc\"\n",
        "    fi\n",
        "\n",
        "    if [ -f \"$tn\" ] && [ -f \"$tx\" ]; then\n",
        "        cdo -expr,tasrange=\"(( tasmax - tasmin ) > 0 ) ? ( tasmax - tasmin ) : ( tasmin - tasmax )\" -merge $tn $tx $tasrange\n",
        "        cdo -expr,tasskew=\" ( tas - tasmin ) / ( tasmax - tasmin ) \" -merge $tn $tx $tas $tasskew\n",
        "\n",
        "        # Processing tasrange and tasskew files\n",
        "        for file in \"$tasrange\" \"$tasskew\"; do\n",
        "            n_times=$(cdo ntime \"$filename\" | awk 'NR==1 {print $1}')\n",
        "            ncpdq -4 -O --cnk_plc=g3d --cnk_dmn=time,$n_times --cnk_dmn=lat,$n_lats --cnk_dmn=lon,$n_lons -a lon,lat,time $file \"${output_dir}/step_7/EFAS_$(basename \"$file\" .nc).nc\"\n",
        "        done\n",
        "    else\n",
        "        echo \"Files $tn or $tx do not exist, skipping...\"\n",
        "    fi\n",
        "done\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8. Bias adjustment and statistical downscaling\n",
        "<a id=\"Step-8-secondary-processing-emo-1-ba\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The final step is to run the adapted script from Stefan Lange [ISIMIP3BASDv3.0.2](https://zenodo.org/records/7151476) for bias adjustment and statistical downscaling of ERA5-Land data based on finer resolution EMO-1 data that is processed in step 6 combined with the coarser resolution EMO-1 data which was converted to same resolution as ERA5-Land in step 6. By doing so, the ERA5-Land can be downscaled to same resolution as that of EMO-1. \n",
        "\n",
        "Note: The script is time-consuming and may take several days to complete depending on the computational resources. It is not recommended to stop the script during the process as it may corrupt the ouput files. Hence, it is recommended to run it on a hosted server or cloud based services if such resources are available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "## this is an adapted script from Stefan Lange for running BASD on ERA5Land and EMO1 files\n",
        "\n",
        "# all vars and time periods\n",
        "vars=\"hurs pr rsds sfcWind tas tasrange tasskew\"\n",
        "pers=\"1950_1989 1990_2022\"\n",
        "\n",
        "# place the downloaded script in the output_dir\n",
        "cdir=\"${output_dir}/isimip3basd-master/code\"\n",
        "idir_era5=\"${output_dir}/step_5\"\n",
        "idir_emo=\"${output_dir}/step_7\"\n",
        "odir=\"${output_dir}/step_8\"\n",
        "\n",
        "# Activate environment once before loop (optional command incase you are using virtual environment in linux/conda or other)\n",
        "#source env/bin/activate\n",
        "\n",
        "# Iterate over all variables and periods\n",
        "for var in $vars; do\n",
        "  for per in $pers; do\n",
        "    echo \"Processing var: $var, period: $per\"\n",
        "    \n",
        "    # Define file paths\n",
        "    obs_hist_fine=$idir_emo/EFAS_${var}_1990_2022_t.nc\n",
        "    obs_hist_coarse=$idir_emo/EFAS_${var}_1990_2022_t_aggregate.nc\n",
        "    sim_hist_coarse=$idir_era5/ERA5_${var}_ERA5_1990_2022_t.nc\n",
        "    sim_fut_coarse=$idir_era5/ERA5_${var}_ERA5_${per}_t.nc\n",
        "    sim_fut_basd_coarse=$odir/ERA5_${var}_ERA5_${per}_t_ba.nc\n",
        "    sim_fut_basd_fine=$odir/ERA5_${var}_ERA5_${per}_t_basd.nc\n",
        "    \n",
        "    # Set parameters based on variable\n",
        "    case $var in\n",
        "      hurs*)\n",
        "        options_ba=\"-v hurs --lower-bound 0 --lower-threshold .01 --upper-bound 100 --upper-threshold 99.99 -t bounded --unconditional-ccs-transfer 1 --trendless-bound-frequency 1\"\n",
        "        options_sd=\"-v hurs --lower-bound 0 --lower-threshold .01 --upper-bound 100 --upper-threshold 99.99\";;\n",
        "      pr*)\n",
        "        options_ba=\"-v pr --lower-bound 0 --lower-threshold .0000011574 --distribution gamma -t mixed\"\n",
        "        options_sd=\"-v pr --lower-bound 0 --lower-threshold .0000011574\";;\n",
        "      rsds*)\n",
        "        options_ba=\"-v rsds --lower-bound 0 --lower-threshold .0001 --upper-bound 1 --upper-threshold .9999 -t bounded -w 15\"\n",
        "        options_sd=\"-v rsds --lower-bound 0 --lower-threshold .01\";;\n",
        "      sfcWind*)\n",
        "        options_ba=\"-v sfcWind --lower-bound 0 --lower-threshold .01 --distribution weibull -t mixed\"\n",
        "        options_sd=\"-v sfcWind --lower-bound 0 --lower-threshold .01\";;\n",
        "      tas)\n",
        "        options_ba=\"-v tas --distribution normal -t additive -d 1\"\n",
        "        options_sd=\"-v tas\";;\n",
        "      tasrange)\n",
        "        options_ba=\"-v tasrange --lower-bound 0 --lower-threshold .01 --distribution weibull -t mixed\"\n",
        "        options_sd=\"-v tasrange --lower-bound 0 --lower-threshold .01\";;\n",
        "      tasskew)\n",
        "        options_ba=\"-v tasskew --lower-bound 0 --lower-threshold .0001 --upper-bound 1 --upper-threshold .9999 -t bounded\"\n",
        "        options_sd=\"-v tasskew --lower-bound 0 --lower-threshold .0001 --upper-bound 1 --upper-threshold .9999\";;\n",
        "      *)\n",
        "        echo \"Variable $var not supported ... aborting ...\"\n",
        "        exit 1;;\n",
        "    esac\n",
        "\n",
        "    # Perform bias adjustment\n",
        "    time python -u $cdir/bias_adjustment.py $options_ba \\\n",
        "    --n-processes 16 \\\n",
        "    --randomization-seed 0 \\\n",
        "    --step-size 1 \\\n",
        "    -o $obs_hist_coarse \\\n",
        "    -s $sim_hist_coarse \\\n",
        "    -f $sim_fut_coarse \\\n",
        "    -b $sim_fut_basd_coarse\n",
        "    chmod 664 $sim_fut_basd_coarse\n",
        "    echo\n",
        "\n",
        "    # Perform statistical downscaling\n",
        "    time python -u $cdir/statistical_downscaling.py $options_sd \\\n",
        "    --n-processes 16 \\\n",
        "    --randomization-seed 0 \\\n",
        "    -o $obs_hist_fine \\\n",
        "    -s $sim_fut_basd_coarse \\\n",
        "    -f $sim_fut_basd_fine\n",
        "    chmod 664 $sim_fut_basd_fine\n",
        "    echo\n",
        "  done\n",
        "done\n",
        "\n",
        "# Deactivate environment (optional)\n",
        "#deactivate\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9. Convert Bias-adjusted and downscaled ERA5 to EMO-1 format\n",
        "<a id=\"step-9-convert-bias-adjusted\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 9.1\n",
        "\n",
        "The script will convert BASD ERA5-Land to EMO-1 format from 1950-1989 for every variable. If you are facing memory issues, refer to possible fixes section 1.4.\n",
        "\n",
        "Use this script only for merged data (for example 1990-2022)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "opath=\"${output_dir}/step_9\"\n",
        "\n",
        "## Convert BASD back to EMO-1 format; adapt the script to cover also the 1950-1989 period\n",
        "\n",
        "# Wind\n",
        "filename=\"${output_dir}/step_8/ERA5_sfcWind_ERA5_1950_1989_t_basd.nc\"\n",
        "oname1=\"${opath}t_$(basename \"$filename\" .nc).nc\"\n",
        "ncpdq -O --cnk_plc=uck -a time,lat,lon $filename $oname1\n",
        "\n",
        "for y in {1950..1989}\n",
        "do\n",
        "  oname2=\"${opath}ws_${y}.nc\"\n",
        "  cdo -L -f nc4c -z zip expr,ws=\"sfcWind\" -shifttime,1days -selyear,$y $oname1 $oname2\n",
        "done\n",
        "rm $oname1 || { echo \"Failed to remove $oname1\"; exit 1; }\n",
        "\n",
        "# Temperature\n",
        "tas=\"${output_dir}/step_8/ERA5_tas_ERA5_1950_1989_t_basd.nc\"\n",
        "tasrange=\"${output_dir}/step_8/ERA5_tasrange_ERA5_1950_1989_t_basd.nc\"\n",
        "tas_a=\"${opath}t_$(basename \"$tas\" .nc).nc\"\n",
        "tasrange_a=\"${opath}t_$(basename \"$tasrange\" .nc).nc\"\n",
        "ncpdq -O --cnk_plc=uck -a time,lat,lon $tas $tas_a\n",
        "ncpdq -O --cnk_plc=uck -a time,lat,lon $tasrange $tasrange_a\n",
        "for y in {1950..1989}\n",
        "do\n",
        "  tas_b=\"${opath}ta_$(basename \"$tas\" .nc)_${y}.nc\"\n",
        "  tasrange_b=\"${opath}ta_$(basename \"$tasrange\" .nc)_${y}.nc\"\n",
        "  cdo -L -f nc4c -z zip -selyear,$y $tas_a $tas_b\n",
        "  cdo -L -f nc4c -z zip -selyear,$y $tasrange_a $tasrange_b\n",
        "  tx=\"${opath}tx_${y}.nc\"\n",
        "  tn=\"${opath}tn_${y}.nc\"\n",
        "  cdo -L -f nc4c -z zip expr,tx=\"tas + 0.5 * tasrange - 273.15\" -merge $tas_b $tasrange_b $tx\n",
        "  cdo -L -f nc4c -z zip expr,tn=\"tas - 0.5 * tasrange - 273.15\" -merge $tas_b $tasrange_b $tn\n",
        "  rm $tasrange_b # don't remove tas_b, needed later\n",
        "done\n",
        "rm $tas_a\n",
        "rm $tasrange_a\n",
        "\n",
        "# Radiation\n",
        "filename=\"${output_dir}/step_8/ERA5_rsds_ERA5_1950_1989_t_basd.nc\"\n",
        "oname1=\"${opath}t_$(basename \"$filename\" .nc).nc\"\n",
        "ncpdq -O --cnk_plc=uck -a time,lat,lon $filename $oname1\n",
        "for y in {1950..1989}\n",
        "do\n",
        "  oname2=\"${opath}rg_${y}.nc\"\n",
        "  cdo -L -f nc4c -z zip expr,rg=\"rsds * 86400\" -shifttime,1days -selyear,$y $oname1 $oname2\n",
        "done\n",
        "rm $oname1\n",
        "\n",
        "# Vapour pressure / humidity\n",
        "filename=\"${output_dir}/step_8/ERA5_hurs_ERA5_1950_1989_t_basd.nc\"\n",
        "oname1=\"${opath}t_$(basename \"$filename\" .nc).nc\"\n",
        "ncpdq -O --cnk_plc=uck -a time,lat,lon $filename $oname1\n",
        "\n",
        "for y in {1950..1989}\n",
        "do\n",
        "  oname2=\"${opath}ta_$(basename \"$filename\" .nc)_${y}.nc\"\n",
        "  cdo -L -f nc4c -z zip -selyear,$y $oname1 $oname2\n",
        "  oname3=\"${opath}pd_${y}.nc\"\n",
        "  cdo -L -f nc4c -z zip expr,pd=\"hurs / 100 * (6.11 * 10 ^ (7.5 * (tas - 273.15) / (237.3 + (tas - 273.15))))\" -merge -shifttime,1days -selyear,$y $oname2 -shifttime,630minutes $tas_b $oname3\n",
        "done\n",
        "rm $oname1\n",
        "\n",
        "# Precipitation\n",
        "filename=\"${output_dir}/step_8/ERA5_pr_ERA5_1950_1989_t_basd.nc\"\n",
        "oname1=\"${opath}t_$(basename \"$filename\" .nc).nc\"\n",
        "ncpdq -O --cnk_plc=uck -a time,lat,lon $filename $oname1\n",
        "for y in {1950..1989}\n",
        "do\n",
        "  oname2=\"${opath}pr_${y}.nc\"\n",
        "  cdo -L -f nc4c -z zip mulc,86400 -shifttime,24hours -selyear,$y $oname1 $oname2\n",
        "done\n",
        "rm $oname1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 9.2\n",
        "\n",
        "The script will convert BASD ERA5-Land to EMO-1 format from 1990-2022.\n",
        "\n",
        "Use this script only for merged data (for example 1990-2022)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "opath=\"${output_dir}/step_9\"\n",
        "\n",
        "## convert BASD back to EMO-1 format; adapt the script to cover also the 1990-2022\n",
        "\n",
        "# Wind\n",
        "filename=\"${output_dir}/step_8/ERA5_sfcWind_ERA5_1990_2022_t_basd.nc\"\n",
        "oname1=\"${opath}t_$(basename \"$filename\" .nc).nc\"\n",
        "ncpdq -O --cnk_plc=uck -a time,lat,lon $filename $oname1\n",
        "\n",
        "for y in {1990..2022}\n",
        "do\n",
        "  oname2=\"${opath}ws_${y}.nc\"\n",
        "  cdo -L -f nc4c -z zip expr,ws=\"sfcWind\" -shifttime,1days -selyear,$y $oname1 $oname2\n",
        "done\n",
        "rm $oname1 || { echo \"Failed to remove $oname1\"; exit 1; }\n",
        "\n",
        "# Temperature\n",
        "tas=\"${output_dir}/step_8/ERA5_tas_ERA5_1990_2022_t_basd.nc\"\n",
        "tasrange=\"${output_dir}/step_8/ERA5_tasrange_ERA5_1990_2022_t_basd.nc\"\n",
        "tas_a=\"${opath}t_$(basename \"$tas\" .nc).nc\"\n",
        "tasrange_a=\"${opath}t_$(basename \"$tasrange\" .nc).nc\"\n",
        "ncpdq -O --cnk_plc=uck -a time,lat,lon $tas $tas_a\n",
        "ncpdq -O --cnk_plc=uck -a time,lat,lon $tasrange $tasrange_a\n",
        "for y in {1990..2022}\n",
        "do\n",
        "  tas_b=\"${opath}ta_$(basename \"$tas\" .nc)_${y}.nc\"\n",
        "  tasrange_b=\"${opath}ta_$(basename \"$tasrange\" .nc)_${y}.nc\"\n",
        "  cdo -L -f nc4c -z zip -selyear,$y $tas_a $tas_b\n",
        "  cdo -L -f nc4c -z zip -selyear,$y $tasrange_a $tasrange_b\n",
        "  tx=\"${opath}tx_${y}.nc\"\n",
        "  tn=\"${opath}tn_${y}.nc\"\n",
        "  cdo -L -f nc4c -z zip expr,tx=\"tas + 0.5 * tasrange - 273.15\" -merge $tas_b $tasrange_b $tx\n",
        "  cdo -L -f nc4c -z zip expr,tn=\"tas - 0.5 * tasrange - 273.15\" -merge $tas_b $tasrange_b $tn\n",
        "  rm $tasrange_b # don't remove tas_b, needed later\n",
        "done\n",
        "rm $tas_a\n",
        "rm $tasrange_a\n",
        "\n",
        "## Radiation\n",
        "filename=\"${output_dir}/step_8/ERA5_rsds_ERA5_1990_2022_t_basd.nc\"\n",
        "oname1=\"${opath}t_$(basename \"$filename\" .nc).nc\"\n",
        "ncpdq -O --cnk_plc=uck -a time,lat,lon $filename $oname1\n",
        "for y in {1990..2022}\n",
        "do\n",
        "  oname2=\"${opath}rg_${y}.nc\"\n",
        "  cdo -L -f nc4c -z zip expr,rg=\"rsds * 86400\" -shifttime,1days -selyear,$y $oname1 $oname2\n",
        "done\n",
        "rm $oname1\n",
        "\n",
        "## Vapour pressure / humidity\n",
        "filename=\"${output_dir}/step_8/ERA5_hurs_ERA5_1990_2022_t_basd.nc\"\n",
        "oname1=\"${opath}t_$(basename \"$filename\" .nc).nc\"\n",
        "ncpdq -O --cnk_plc=uck -a time,lat,lon $filename $oname1\n",
        "\n",
        "for y in {1990..2022}\n",
        "do\n",
        "  oname2=\"${opath}ta_$(basename \"$filename\" .nc)_${y}.nc\"\n",
        "  cdo -L -f nc4c -z zip -selyear,$y $oname1 $oname2\n",
        "  oname3=\"${opath}pd_${y}.nc\"\n",
        "  cdo -L -f nc4c -z zip expr,pd=\"hurs / 100 * (6.11 * 10 ^ (7.5 * (tas - 273.15) / (237.3+ (tas - 273.15) ) ))\" -merge -shifttime,1days -selyear,$y $oname2 -shifttime,630minutes $tas_b $oname3\n",
        "done\n",
        "rm $oname1\n",
        "\n",
        "## Precipitation\n",
        "filename=\"${output_dir}/step_8/ERA5_pr_ERA5_1990_2022_t_basd.nc\"\n",
        "oname1=\"${opath}t_$(basename \"$filename\" .nc).nc\"\n",
        "ncpdq -O --cnk_plc=uck -a time,lat,lon $filename $oname1\n",
        "for y in {1990..2022}\n",
        "do\n",
        "  oname2=\"${opath}pr_${y}.nc\"\n",
        "  cdo -L -f nc4c -z zip mulc,86400 -shifttime,24hours -selyear,$y $oname1 $oname2\n",
        "done\n",
        "rm $oname1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 9.3 (optional for a single year, for example 2023)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "opath=\"${output_dir}/step_9/\"\n",
        "\n",
        "###################################### \n",
        "#            1\n",
        "######################################\n",
        " Temperature\n",
        "tas=\"${output_dir}/step_8/ERA5_tas_ERA5_2023_basd.nc\"\n",
        "tasrange=\"${output_dir}/step_8/ERA5_tasrange_ERA5_2023_basd.nc\"\n",
        "tas_a=\"${opath}t_$(basename \"$tas\" .nc).nc\"\n",
        "tasrange_a=\"${opath}t_$(basename \"$tasrange\" .nc).nc\"\n",
        "ncpdq -O --cnk_plc=uck -a time,lat,lon $tas $tas_a\n",
        "ncpdq -O --cnk_plc=uck -a time,lat,lon $tasrange $tasrange_a\n",
        "for y in {2023..2023}\n",
        "do\n",
        "  tas_b=\"${opath}ta_$(basename \"$tas\" .nc)_${y}.nc\"\n",
        "  tasrange_b=\"${opath}ta_$(basename \"$tasrange\" .nc)_${y}.nc\"\n",
        "  cdo -L -f nc4c -z zip -selyear,$y $tas_a $tas_b\n",
        "  cdo -L -f nc4c -z zip -selyear,$y $tasrange_a $tasrange_b\n",
        "  tx=\"${opath}tx_${y}.nc\"\n",
        "  tn=\"${opath}tn_${y}.nc\"\n",
        "  cdo -L -f nc4c -z zip expr,tx=\"tas + 0.5 * tasrange - 273.15\" -merge $tas_b $tasrange_b $tx\n",
        "  cdo -L -f nc4c -z zip expr,tn=\"tas - 0.5 * tasrange - 273.15\" -merge $tas_b $tasrange_b $tn\n",
        "  rm $tasrange_b # don't remove tas_b, needed later\n",
        "done\n",
        "rm $tas_a\n",
        "rm $tasrange_a\n",
        "\n",
        "\n",
        "# Vapour pressure / humidity\n",
        "filename=\"${output_dir}/step_8/ERA5_hurs_ERA5_2023_basd.nc\"\n",
        "oname1=\"${opath}t_$(basename \"$filename\" .nc).nc\"\n",
        "ncpdq -O --cnk_plc=uck -a time,lat,lon $filename $oname1\n",
        "\n",
        "for y in {2023..2023}\n",
        "do\n",
        "  oname2=\"${opath}ta_$(basename \"$filename\" .nc)_${y}.nc\"\n",
        "  cdo -L -f nc4c -z zip -selyear,$y $oname1 $oname2\n",
        "  oname3=\"${opath}pd_${y}.nc\"\n",
        "  cdo -L -f nc4c -z zip expr,pd=\"hurs / 100 * (6.11 * 10 ^ (7.5 * (tas - 273.15) / (237.3+ (tas - 273.15) ) ))\" -merge -shifttime,1days -selyear,$y $oname2 -shifttime,630minutes $tas_b $oname3\n",
        "done\n",
        "rm $oname1\n",
        "#\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "###################################### \n",
        "#            2\n",
        "######################################\n",
        "\n",
        "# Radiation\n",
        "filename=\"${output_dir}/step_8/ERA5_rsds_ERA5_2023_basd.nc\"\n",
        "oname1=\"${opath}t_$(basename \"$filename\" .nc).nc\"\n",
        "ncpdq -O --cnk_plc=uck -a time,lat,lon $filename $oname1\n",
        "for y in {2023..2023}\n",
        "do\n",
        "  oname2=\"${opath}rg_${y}.nc\"\n",
        "  cdo -L -f nc4c -z zip expr,rg=\"rsds * 86400\" -shifttime,1days -selyear,$y $oname1 $oname2\n",
        "done\n",
        "rm $oname1\n",
        "\n",
        "# Wind\n",
        "filename=\"${output_dir}/step_8/ERA5_sfcWind_ERA5_2023_basd.nc\"\n",
        "oname1=\"${opath}t_$(basename \"$filename\" .nc).nc\"\n",
        "ncpdq -O --cnk_plc=uck -a time,lat,lon $filename $oname1\n",
        "\n",
        "for y in {2023..2023}\n",
        "do\n",
        "  oname2=\"${opath}ws_${y}.nc\"\n",
        "  cdo -L -f nc4c -z zip expr,ws=\"sfcWind\" -shifttime,1days -selyear,$y $oname1 $oname2\n",
        "done\n",
        "rm $oname1 || { echo \"Failed to remove $oname1\"; exit 1; }\n",
        "\n",
        "#\n",
        "# Precipitation\n",
        "filename=\"${output_dir}/step_8/ERA5_pr_ERA5_2023_basd.nc\"\n",
        "oname1=\"${opath}t_$(basename \"$filename\" .nc).nc\"\n",
        "ncpdq -O --cnk_plc=uck -a time,lat,lon $filename $oname1\n",
        "for y in {2023..2023}\n",
        "do\n",
        "  oname2=\"${opath}pr_${y}.nc\"\n",
        "  cdo -L -f nc4c -z zip mulc,86400 -shifttime,24hours -selyear,$y $oname1 $oname2\n",
        "done\n",
        "rm $oname1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 10. Final post-processing of ERA-5 files for consistency with EMO-1 data\n",
        "<a id=\"step-10-final-post-processing\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"https://naturalhazards.eu/timeshift.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 10.1\n",
        "The script defines input, output, and intermediate file paths for the processing of meteorological variables (1950 to 2022). The ipath, epath, and opath variables designate paths for the input files, ERA5 climate data, and output files, respectively.\n",
        "\n",
        "The script performs several tasks in a loop over each year. It starts by computing a land mask for the BASD dataset, then extracts grid information and calculates regridding weights for the ERA5 data. For each year, the script processes the variable files by setting up file names for input and output. It handles the regridding of ERA5 files to match the BASD grid, adjusting for time shifts where necessary. It converts relative humidity (hurs) into partial pressure (pd) for certain variables and ensures consistency in units and time shifts across files.\n",
        "\n",
        "The script also corrects the time vector, processes and compresses data using cdo commands for specific meteorological variables, and applies transformations such as packing values into smaller byte formats and adjusting chunking for NetCDF outputs. The time units are adapted depending on the time period (1950-1989 or 1990-2022), and temporary files are removed at the end of each iteration.\n",
        "\n",
        "The script requires specific adjustments for each variable where the user needs to add some expressions and different timestamps to modify the data to match with that of EMO1. The code snippets for each variable has been provided seperately below for convenience.\n",
        "\n",
        "The below script is for `ws` variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "ipath=\"${output_dir}/step_9/\"\n",
        "epath=\"${output_dir}/step_2/ERA5_for_gapfill/\"\n",
        "opath=\"${output_dir}/step_10/\"\n",
        "\n",
        "## compute BASD landmask, grid and weights for regridding ERA% (only needed once, the same files are used for other variables)\n",
        "basd_file=\"${ipath}ws_1951.nc\" # from step 9\n",
        "basd_mask=\"${opath}basd_landmask.nc\"\n",
        "cdo -f nc4c -z zip setmisstoc,0 -expr,sfcWind=\"(ws >= 0) ? 1 : 0\" -seltimestep,1 $basd_file $basd_mask\n",
        "grid_file=\"${opath}basd_grid.txt\"\n",
        "cdo griddes $basd_file > $grid_file\n",
        "weight_file=\"${opath}ERA5_weights.nc\"\n",
        "era5_file=\"${epath}tasmax_ERA5_1951.nc\" # from step 2\n",
        "cdo gennn,$grid_file $era5_file $weight_file\n",
        "\n",
        "# dimension (adapt n_lats and n_longs to file dimensions divided by 3)\n",
        "n_times=1\n",
        "n_lats=990\n",
        "n_lons=1510\n",
        "\n",
        "## loop to repeat per variable\n",
        "for y in {1950..2020}\n",
        "do\n",
        "\tfilename=\"${ipath}ws_${y}.nc\" # from step 9\n",
        "\ttile=\"$(echo $(basename \"$filename\" .nc) | cut -d'_' -f2)\"\n",
        "\tera5_file=\"${epath}sfcWind_ERA5_${tile}.nc\" # from step 2\n",
        "\tera5_file_regrid=\"${epath}regrid_sfcWind_ERA5_${tile}.nc\"\n",
        "\toname1=\"${opath}tb_$(basename \"$filename\" .nc).nc\"\n",
        "\toname2=\"${opath}tc_$(basename \"$filename\" .nc).nc\"\n",
        "\toname3=\"${opath}td_$(basename \"$filename\" .nc).nc\"\n",
        "\toname4=\"${opath}te_$(basename \"$filename\" .nc).nc\"\n",
        "\toname5=\"${opath}$(basename \"$filename\" .nc).nc\"\n",
        "\n",
        "\tcdo -f nc4c -z zip remap,$grid_file,$weight_file -shifttime,1days $era5_file $era5_file_regrid\n",
        "\n",
        "\n",
        "\tcdo -f nc4c -z zip ifthenelse $basd_mask $filename $era5_file_regrid $oname1\n",
        "\tcdo -f nc4c -z zip shifttime,-330minutes $oname1 $oname2\n",
        "\n",
        "\tncatted -O -a _FillValue,ws,o,s,-9999 $oname2\n",
        "\tncatted -O -a missing_value,ws,o,s,-9999 $oname2\n",
        "\n",
        "\tncap2 -v -O -s 'ws=pack(ws,0.1,0);' $oname2 $oname3\n",
        "\tncpdq -O --cnk_plc=g3d --cnk_dmn=time,$n_times --cnk_dmn=lat,$n_lats --cnk_dmn=lon,$n_lons -a time,lat,lon $oname3 $oname4\n",
        "\tncap2 -O -s 'time=(time-24)/24;' $oname4 $oname5\n",
        "\tncatted -a units,time,o,c,\"days since 1990-01-01 00:00:00\" $oname5\n",
        "\t## 1950-1989: ncatted -a units,time,o,c,\"days since 1950-01-02 00:00:00\" $oname5\n",
        "\n",
        "  # remove temporary files\n",
        "\trm t*_ws_*.nc\n",
        "done"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To verify if the time steps are correct, use command cdo info {path_to_nc.nc} and do the same for EMO-1 file to confirm that the timestamps are consistent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 10.2\n",
        "The initial code needs to be modified with expr command and other modifications necessary to add consistency in the units between EMO-1 and ERA-5 data. Therefore, below are the changes that need to be made to ensure that every variable is gap-filled and processed without any errors.\n",
        "\n",
        "`pd`:\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "ipath=\"${output_dir}/step_9/\"\n",
        "epath=\"${output_dir}/step_2/ERA5_for_gapfill/\"\n",
        "opath=\"${output_dir}/step_10/\"\n",
        "\n",
        "## compute BASD landmask, grid and weights for regridding ERA% (only needed once, the same files are used for other variables)\n",
        "basd_file=\"${ipath}pd_1951.nc\" # from step 9\n",
        "basd_mask=\"${opath}basd_landmask_pl2.nc\"\n",
        "grid_file=\"${opath}basd_grid.txt\"\n",
        "cdo griddes $basd_file > $grid_file\n",
        "weight_file=\"${opath}ERA5_weights.nc\"\n",
        "era5_file=\"${epath}hurs_ERA5_1951.nc\" # from step 2\n",
        "cdo gennn,$grid_file $era5_file $weight_file\n",
        "\n",
        "# dimension (adapt n_lats and n_longs to file dimensions divided by 3)\n",
        "n_times=1\n",
        "n_lats=142\n",
        "n_lons=262\n",
        "\n",
        "## loop to repeat per variable\n",
        "for y in {1950..1989}\n",
        "do\n",
        "\tfilename=\"${ipath}pd_${y}.nc\" # from step 9\n",
        "\ttile=\"$(echo $(basename \"$filename\" .nc) | cut -d'_' -f2)\"\n",
        "\tera5_file=\"${epath}hurs_ERA5_${tile}.nc\" # from step 2\n",
        "\tera5_file_regrid=\"${epath}regrid_hurs_ERA5_${tile}.nc\"\n",
        "\toname1=\"${opath}tb_$(basename \"$filename\" .nc).nc\"\n",
        "\toname2=\"${opath}tc_$(basename \"$filename\" .nc).nc\"\n",
        "\toname3=\"${opath}td_$(basename \"$filename\" .nc).nc\"\n",
        "\toname4=\"${opath}te_$(basename \"$filename\" .nc).nc\"\n",
        "\toname5=\"${opath}$(basename \"$filename\" .nc).nc\"\n",
        "\n",
        "  \tera5_file_tas=\"${epath}tas_ERA5_${tile}.nc\"\n",
        "\tera5_file_pd=\"${epath}pd_ERA5_${tile}.nc\"\n",
        "\n",
        "\t\"\"\"\n",
        "\tAdded expr,pd=\"hurs / 100 * (6.11 * 10 ^ (7.5 * (dpt - 273.15) / (237.3 + (dpt - 273.15) ) ))\" \n",
        "\tto calculate the actual vapor pressure which is used in EMO-1 data.\n",
        "\n",
        "\t\"\"\"\n",
        "\tcdo -f nc4c -z zip expr,pd=\"hurs / 100 * (6.11 * 10 ^ (7.5 * (dpt - 273.15) / (237.3 + (dpt - 273.15) ) ))\" -merge $era5_file $era5_file_tas $era5_file_pd\n",
        "\n",
        "\tcdo -f nc4c -z zip remap,$grid_file,$weight_file -shifttime,1days $era5_file_pd $era5_file_regrid\n",
        "\n",
        "\tcdo -f nc4c -z zip ifthenelse $basd_mask $filename $era5_file_regrid $oname1\n",
        "\tcdo -f nc4c -z zip shifttime,-690minutes $oname1 $oname2\n",
        "\n",
        "\tncatted -O -a _FillValue,pd,o,s,-9999 $oname2\n",
        "\tncatted -O -a missing_value,pd,o,s,-9999 $oname2\n",
        "\n",
        "\tncap2 -v -O -s 'pd=pack(pd,0.1,0);' $oname2 $oname3\n",
        "\tncpdq -O --cnk_plc=g3d --cnk_dmn=time,$n_times --cnk_dmn=lat,$n_lats --cnk_dmn=lon,$n_lons -a time,lat,lon $oname3 $oname4\n",
        "\tncap2 -O -s 'time=(time-24)/24;' $oname4 $oname5\n",
        "\tncatted -a units,time,o,c,\"days since 1950-01-02 00:00:00\" $oname5\n",
        "\t#ncatted -a units,time,o,c,\"days since 1990-01-01 00:00:00\" $oname5\n",
        "\t\n",
        "  # remove temporary files\n",
        "rm t*_pd*.nc\n",
        "done"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`pr`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "ipath=\"${output_dir}/step_9/\"\n",
        "epath=\"${output_dir}/step_2/ERA5_for_gapfill/\"\n",
        "opath=\"${output_dir}/step_10/\"\n",
        "\n",
        "## compute BASD landmask, grid and weights for regridding ERA% (only needed once, the same files are used for other variables)\n",
        "basd_file=\"${ipath}pr_1951.nc\" # from step 9\n",
        "basd_mask=\"${opath}basd_landmask_pl2.nc\"\n",
        "grid_file=\"${opath}basd_grid.txt\"\n",
        "cdo griddes $basd_file > $grid_file\n",
        "weight_file=\"${opath}ERA5_weights.nc\"\n",
        "era5_file=\"${epath}pr_ERA5_1951.nc\" # from step 2\n",
        "cdo gennn,$grid_file $era5_file $weight_file\n",
        "\n",
        "# dimension (adapt n_lats and n_longs to file dimensions divided by 3)\n",
        "n_times=1\n",
        "n_lats=142\n",
        "n_lons=262\n",
        "\n",
        "## loop to repeat per variable\n",
        "for y in {1950..1989}\n",
        "do\n",
        "\tfilename=\"${ipath}pr_${y}.nc\" # from step 9\n",
        "\ttile=\"$(echo $(basename \"$filename\" .nc) | cut -d'_' -f2)\"\n",
        "\tera5_file=\"${epath}pr_ERA5_${tile}.nc\" # from step 2\n",
        "\tera5_file_regrid=\"${epath}regrid_pr_ERA5_${tile}.nc\"\n",
        "\toname1=\"${opath}tb_$(basename \"$filename\" .nc).nc\"\n",
        "\toname2=\"${opath}tc_$(basename \"$filename\" .nc).nc\"\n",
        "\toname3=\"${opath}td_$(basename \"$filename\" .nc).nc\"\n",
        "\toname4=\"${opath}te_$(basename \"$filename\" .nc).nc\"\n",
        "\toname5=\"${opath}$(basename \"$filename\" .nc).nc\"\n",
        "\n",
        "\t\"\"\"\n",
        "\tAdded -expr,pr=\"pr*86400\" for consistency between the units in EMO-1 and ERA-5\n",
        "\t\n",
        "\t\"\"\"\n",
        "\n",
        "\tcdo -f nc4c -z zip remap,$grid_file,$weight_file -expr,pr=\"pr*86400\" -shifttime,1days $era5_file $era5_file_regrid\n",
        "\n",
        "\tcdo -f nc4c -z zip ifthenelse $basd_mask $filename $era5_file_regrid $oname1\n",
        "\tcdo -f nc4c -z zip shifttime,360minutes $oname1 $oname2\n",
        "\n",
        "\tncatted -O -a _FillValue,pr,o,s,-9999 $oname2\n",
        "\tncatted -O -a missing_value,pr,o,s,-9999 $oname2\n",
        "\n",
        "\tncap2 -v -O -s 'pr=pack(pr,0.1,0);' $oname2 $oname3\n",
        "\tncpdq -O --cnk_plc=g3d --cnk_dmn=time,$n_times --cnk_dmn=lat,$n_lats --cnk_dmn=lon,$n_lons -a time,lat,lon $oname3 $oname4\n",
        "\tncap2 -O -s 'time=(time-24)/24;' $oname4 $oname5\n",
        "\tncatted -a units,time,o,c,\"days since 1950-01-02 00:00:00\" $oname5\n",
        "\t#ncatted -a units,time,o,c,\"days since 1990-01-01 00:00:00\" $oname5\n",
        "\n",
        "  # remove temporary files\n",
        "rm t*_pr_*.nc\n",
        "done"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`rg`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "ipath=\"${output_dir}/step_9/\"\n",
        "epath=\"${output_dir}/step_2/ERA5_for_gapfill/\"\n",
        "opath=\"${output_dir}/step_10/\"\n",
        "\n",
        "## compute BASD landmask, grid and weights for regridding ERA% (only needed once, the same files are used for other variables)\n",
        "basd_file=\"${ipath}rg_1951.nc\" # from step 9\n",
        "basd_mask=\"${opath}basd_landmask_pl2.nc\"\n",
        "#cdo -f nc4c -z zip expr,tas=\"(tn >= 0) ? 1 : 0\" -seltimestep,1 $basd_file $basd_mask\n",
        "grid_file=\"${opath}basd_grid.txt\"\n",
        "cdo griddes $basd_file > $grid_file\n",
        "weight_file=\"${opath}ERA5_weights.nc\"\n",
        "era5_file=\"${epath}rsds_ERA5_1951.nc\" # from step 2\n",
        "cdo gennn,$grid_file $era5_file $weight_file\n",
        "\n",
        "# dimension (adapt n_lats and n_longs to file dimensions divided by 3)\n",
        "n_times=1\n",
        "n_lats=142\n",
        "n_lons=262\n",
        "\n",
        "## loop to repeat per variable\n",
        "for y in {1950..1950}\n",
        "do\n",
        "\tfilename=\"${ipath}rg_${y}.nc\" # from step 9\n",
        "\ttile=\"$(echo $(basename \"$filename\" .nc) | cut -d'_' -f2)\"\n",
        "\tera5_file=\"${epath}rsds_ERA5_${tile}.nc\" # from step 2\n",
        "\tera5_file_regrid=\"${epath}regrid_rsds_ERA5_${tile}.nc\"\n",
        "\toname1=\"${opath}tb_$(basename \"$filename\" .nc).nc\"\n",
        "\toname2=\"${opath}tc_$(basename \"$filename\" .nc).nc\"\n",
        "\toname3=\"${opath}td_$(basename \"$filename\" .nc).nc\"\n",
        "\toname4=\"${opath}te_$(basename \"$filename\" .nc).nc\"\n",
        "\toname5=\"${opath}$(basename \"$filename\" .nc).nc\"\n",
        "\n",
        "\t\"\"\"\n",
        "\tAdded -expr,rg=\"rg*86400\" for consistency between the units in EMO-1 and ERA-5\n",
        "\t\n",
        "\t\"\"\"\n",
        "\tcdo -f nc4c -z zip remap,$grid_file,$weight_file -expr,rg=\"rg*86400\" -shifttime,1days $era5_file $era5_file_regrid\n",
        "\n",
        "\tcdo -f nc4c -z zip ifthenelse $basd_mask $filename $era5_file_regrid $oname1\n",
        "\tcdo -f nc4c -z zip shifttime,0minutes $oname1 $oname2\n",
        "\n",
        "\tncatted -O -a _FillValue,rg,o,s,-9999 $oname2\n",
        "\tncatted -O -a missing_value,rg,o,s,-9999 $oname2\n",
        "\n",
        "\tncap2 -v -O -s 'rg=pack(rg,10000,0);' $oname2 $oname3\n",
        "\tncpdq -O --cnk_plc=g3d --cnk_dmn=time,$n_times --cnk_dmn=lat,$n_lats --cnk_dmn=lon,$n_lons -a time,lat,lon $oname3 $oname4\n",
        "\tncap2 -O -s 'time=(time-24)/24;' $oname4 $oname5\n",
        "\tncatted -a units,time,o,c,\"days since 1950-01-02 00:00:00\" $oname5\n",
        "\t## 1950-1989: ncatted -a units,time,o,c,\"days since 1950-01-02 00:00:00\" $oname5\n",
        "\n",
        "  # remove temporary files (optional, can be used to troubleshoot the issues in the code)\n",
        "rm t*_rd_*.nc\n",
        "done"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`tn`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "ipath=\"${output_dir}/step_9/\"\n",
        "epath=\"${output_dir}/step_2/ERA5_for_gapfill/\"\n",
        "opath=\"${output_dir}/step_10/\"\n",
        "\n",
        "## compute BASD landmask, grid and weights for regridding ERA% (only needed once, the same files are used for other variables)\n",
        "basd_file=\"${ipath}tn_1951.nc\" # from step 9\n",
        "basd_mask=\"${opath}basd_landmask_pl2.nc\"\n",
        "grid_file=\"${opath}basd_grid.txt\"\n",
        "cdo griddes $basd_file > $grid_file\n",
        "weight_file=\"${opath}ERA5_weights.nc\"\n",
        "era5_file=\"${epath}tasmin_ERA5_1951.nc\" # from step 2\n",
        "cdo gennn,$grid_file $era5_file $weight_file\n",
        "\n",
        "# dimension (adapt n_lats and n_longs to file dimensions divided by 3)\n",
        "n_times=1\n",
        "n_lats=142\n",
        "n_lons=262\n",
        "\n",
        "## loop to repeat per variable\n",
        "for y in {1950..1989}\n",
        "do\n",
        "\tfilename=\"${ipath}tn_${y}.nc\" # from step 9\n",
        "\ttile=\"$(echo $(basename \"$filename\" .nc) | cut -d'_' -f2)\"\n",
        "\tera5_file=\"${epath}tasmin_ERA5_${tile}.nc\" # from step 2\n",
        "\tera5_file_regrid=\"${epath}regrid_tasmin_ERA5_${tile}.nc\"\n",
        "\toname1=\"${opath}tb_$(basename \"$filename\" .nc).nc\"\n",
        "\toname2=\"${opath}tc_$(basename \"$filename\" .nc).nc\"\n",
        "\toname3=\"${opath}td_$(basename \"$filename\" .nc).nc\"\n",
        "\toname4=\"${opath}te_$(basename \"$filename\" .nc).nc\"\n",
        "\toname5=\"${opath}$(basename \"$filename\" .nc).nc\"\n",
        "\n",
        "\t\"\"\"\n",
        "\tAdded -expr,tn=\"tx-273.15\" to fix the issue that was made earlier in step 2 which replaced tx with tn and tn with tx.\n",
        "\t\n",
        "\t\"\"\"\n",
        "\n",
        "\tcdo -f nc4c -z zip remap,$grid_file,$weight_file -expr,tn=\"tx-273.15\" $era5_file $era5_file_regrid\n",
        "\n",
        "\tcdo -f nc4c -z zip ifthenelse $basd_mask $filename $era5_file_regrid $oname1\n",
        "\tcdo -f nc4c -z zip shifttime,30minutes $oname1 $oname2\n",
        "\n",
        "\tncatted -O -a _FillValue,tn,o,s,-9999 $oname2\n",
        "\tncatted -O -a missing_value,tn,o,s,-9999 $oname2\n",
        "\n",
        "\tncap2 -v -O -s 'tn=pack(tn,0.1,0);' $oname2 $oname3\n",
        "\tncpdq -O --cnk_plc=g3d --cnk_dmn=time,$n_times --cnk_dmn=lat,$n_lats --cnk_dmn=lon,$n_lons -a time,lat,lon $oname3 $oname4\n",
        "\tncap2 -O -s 'time=(time-30)/24;' $oname4 $oname5\n",
        "\tncatted -a units,time,o,c,\"days since 1950-01-02 00:00:00\" $oname5\n",
        "\t## 1950-1989: ncatted -a units,time,o,c,\"days since 1950-01-02 00:00:00\" $oname5\n",
        "\n",
        "  # remove temporary files\n",
        "rm t*_tn_*.nc\n",
        "done"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`tx`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "ipath=\"${output_dir}/step_9/\"\n",
        "epath=\"${output_dir}/step_2/ERA5_for_gapfill/\"\n",
        "opath=\"${output_dir}/step_10/\"\n",
        "\n",
        "## compute BASD landmask, grid and weights for regridding ERA% (only needed once, the same files are used for other variables)\n",
        "basd_file=\"${ipath}tx_1951.nc\" # from step 9\n",
        "basd_mask=\"${opath}basd_landmask_pl2.nc\"\n",
        "grid_file=\"${opath}basd_grid.txt\"\n",
        "cdo griddes $basd_file > $grid_file\n",
        "weight_file=\"${opath}ERA5_weights.nc\"\n",
        "era5_file=\"${epath}tasmax_ERA5_1951.nc\" # from step 2\n",
        "cdo gennn,$grid_file $era5_file $weight_file\n",
        "\n",
        "# dimension (adapt n_lats and n_longs to file dimensions divided by 3)\n",
        "n_times=1\n",
        "n_lats=142\n",
        "n_lons=262\n",
        "\n",
        "## loop to repeat per variable\n",
        "for y in {1950..1989}\n",
        "do\n",
        "\tfilename=\"${ipath}tx_${y}.nc\" # from step 9\n",
        "\ttile=\"$(echo $(basename \"$filename\" .nc) | cut -d'_' -f2)\"\n",
        "\tera5_file=\"${epath}tasmax_ERA5_${tile}.nc\" # from step 2\n",
        "\tera5_file_regrid=\"${epath}regrid_tasmax_ERA5_${tile}.nc\"\n",
        "\toname1=\"${opath}tb_$(basename \"$filename\" .nc).nc\"\n",
        "\toname2=\"${opath}tc_$(basename \"$filename\" .nc).nc\"\n",
        "\toname3=\"${opath}td_$(basename \"$filename\" .nc).nc\"\n",
        "\toname4=\"${opath}te_$(basename \"$filename\" .nc).nc\"\n",
        "\toname5=\"${opath}$(basename \"$filename\" .nc).nc\"\n",
        "\n",
        "\t\"\"\"\n",
        "\tAdded -expr,tn=\"tx-273.15\" to fix the issue that was made earlier in step 2 which replaced tx with tn and tn with tx.\n",
        "\t\n",
        "\t\"\"\"\n",
        "\n",
        "\tcdo -f nc4c -z zip remap,$grid_file,$weight_file -expr,tx=\"tn-273.15\" $era5_file $era5_file_regrid\n",
        "\n",
        "\tcdo -f nc4c -z zip ifthenelse $basd_mask $filename $era5_file_regrid $oname1\n",
        "\tcdo -f nc4c -z zip shifttime,390minutes $oname1 $oname2\n",
        "\n",
        "\tncatted -O -a _FillValue,tx,o,s,-9999 $oname2\n",
        "\tncatted -O -a missing_value,tx,o,s,-9999 $oname2\n",
        "\n",
        "\tncap2 -v -O -s 'tx=pack(tx,0.1,0);' $oname2 $oname3\n",
        "\tncpdq -O --cnk_plc=g3d --cnk_dmn=time,$n_times --cnk_dmn=lat,$n_lats --cnk_dmn=lon,$n_lons -a time,lat,lon $oname3 $oname4\n",
        "\tncap2 -O -s 'time=(time-24)/24;' $oname4 $oname5\n",
        "\tncatted -a units,time,o,c,\"days since 1950-01-02 00:00:00\" $oname5\n",
        "\t## 1950-1989: ncatted -a units,time,o,c,\"days since 1950-01-02 00:00:00\" $oname5\n",
        "\n",
        "  # remove temporary files\n",
        "rm t*_tx_*.nc\n",
        "done"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 10.3\n",
        "Calculation of the annual mean. <br/>\n",
        "You need to SHP file with Province coordinates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import geopandas as gpd\n",
        "import xarray as xr\n",
        "import rioxarray\n",
        "import numpy as np\n",
        "from rasterio.features import geometry_mask\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "\n",
        "input_dir='/LOCATION-TO-YOUR-FOLDER/compass_framework'  # Keep location of Python to compass_framework folder\n",
        "\n",
        "# Load the shapefile\n",
        "shapefile_path = '${input_dir}/step_10/shp/voivodeships.shp' \n",
        "poland_shapefile = gpd.read_file(shapefile_path)\n",
        "\n",
        "\n",
        "# List of variables and years you want to process\n",
        "variables = ['tx', 'tn', 'pd', 'ws', 'rg', 'pr']  # 'tx', 'tn', 'pd', 'ws', 'rg', 'pr'\n",
        "years = range(1950, 2024)  # range\n",
        "\n",
        "# Directory where your NetCDF files are located\n",
        "netcdf_dir = '${input_dir}/step_10/'\n",
        "\n",
        "# Directory where you want to save the output CSV files\n",
        "output_dir = '${input_dir}/step_10/mean-y/'\n",
        "\n",
        "# Make sure the output directory exists\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# List to store results for CSV output\n",
        "results = []\n",
        "\n",
        "# Loop through each variable\n",
        "for variable in variables:\n",
        "\n",
        "    # Loop through each year and load the NetCDF file\n",
        "    for year in years:\n",
        "        netcdf_file = f'{netcdf_dir}{variable}_{year}.nc'\n",
        "        \n",
        "        # Check if file exist\n",
        "        if not os.path.exists(netcdf_file):\n",
        "            print(f\"File {netcdf_file} not found, skipping this year.\")\n",
        "            continue\n",
        "        \n",
        "        # Open the dataset\n",
        "        data = xr.open_dataset(netcdf_file)\n",
        "        \n",
        "        # Access the specific variable (e.g., 'tx' for maximum daily temperature)\n",
        "        var_data = data[variable]\n",
        "        \n",
        "        # Make sure the data has proper geospatial coordinates\n",
        "        var_data = var_data.rio.write_crs(\"EPSG:4326\")\n",
        "\n",
        "        # Loop through each voivodeship\n",
        "        for idx, voivodeship in poland_shapefile.iterrows():\n",
        "            # Get the geometry (boundary) of the voivodeship\n",
        "            geometry = [voivodeship['geometry']]\n",
        "            \n",
        "            # Create a mask for the voivodeship geometry (lat/lon grid is 2D)\n",
        "            mask = geometry_mask([geom for geom in geometry], \n",
        "                                 transform=var_data.rio.transform(), \n",
        "                                 invert=True, \n",
        "                                 out_shape=var_data.shape[-2:])\n",
        "            \n",
        "            # Apply the mask to the entire time series data\n",
        "            masked_data = var_data.where(mask)\n",
        "\n",
        "            # Calculate the mean value at each grid cell across all timestamps\n",
        "            if variable == 'pr':\n",
        "                # For 'pr' \n",
        "                mean_per_grid_cell = masked_data.mean(dim='time') * 365\n",
        "            else:\n",
        "                # For all variables except pr\n",
        "                mean_per_grid_cell = masked_data.mean(dim='time')\n",
        "\n",
        "            # Calculate the mean of these values for the entire region within the voivodeship\n",
        "            mean_max_value = mean_per_grid_cell.mean().item()\n",
        "\n",
        "            # Add the result to the list\n",
        "            results.append({\n",
        "                'variable': variable, \n",
        "                'voivodeship': voivodeship['nazwa'],  \n",
        "                'mean': mean_max_value,  \n",
        "                'year': year  \n",
        "            })\n",
        "\n",
        "# Create a DataFrame from the results\n",
        "df_results = pd.json_normalize(results)\n",
        "df_results['mean'] = df_results['mean'].round(4)\n",
        "df_results = df_results.dropna(subset=['year'])\n",
        "df_results['year'] = df_results['year'].astype(int).astype(str)\n",
        "\n",
        "print(df_results.head())\n",
        "print(df_results.columns)\n",
        "\n",
        "# Save to CSV, one file per variable\n",
        "for variable in variables:\n",
        "    df_var = df_results[df_results['variable'] == variable]\n",
        "    csv_filename = f'{output_dir}{variable}-mean-y.csv'\n",
        "    df_var.to_csv(csv_filename, index=False)\n",
        "\n",
        "print(\"CSV is ready.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 11 Lisvap script\n",
        "\n",
        "To run LISVAP, you will need to install the script <br/>\n",
        "https://ec-jrc.github.io/lisflood-lisvap/3_LISVAP_installation/<br/>\n",
        "In addition, you will need https://pcraster.geo.uu.nl/pcraster/4.4.1/documentation/pcraster_project/install.html\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sample config XML is located in SCRIPT folder.<br/> \n",
        "\n",
        "Oryginal file from Lisvap project might not work properly. Donwload sample config file from SCRIPT folder and change path to your location. Next replace the downloaded config xml with the one in the script and run LISVAP."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Possible fixes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This section contains information about possible fixes or suggestions to prevent the issues that were encountered."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1. Recommended versions on which all the scripts have been tested to run without any issues.\n",
        "\n",
        "| Software               | Version     |\n",
        "|:-----------------------|:------------|\n",
        "| Python                 | 3.11.6      |\n",
        "| Ubuntu                 | 22.04 ([Check WSL2 documentation](https://learn.microsoft.com/en-us/windows/wsl/install) for Linux on Windows)      |\n",
        "| Cartopy                | 0.23.0      |\n",
        "| cdo                    | 2.2.3       |\n",
        "| cdsapi                 | 0.7.0       |\n",
        "| certifi                | 2024.7.4    |\n",
        "| cf-units               | 3.2.0       |\n",
        "| cftime                 | 1.6.4       |\n",
        "| comm                   | 0.2.2       |\n",
        "| contourpy              | 1.2.1       |\n",
        "| cycler                 | 0.12.1      |\n",
        "| debugpy                | 1.8.5       |\n",
        "| decorator              | 5.1.1       |\n",
        "| executing              | 2.0.1       |\n",
        "| exsce                  | 1.5.0       |\n",
        "| ecCodes                | 2.31.1      |\n",
        "| FILE                   | 1.9.1       |\n",
        "| fonttools              | 4.53.1      |\n",
        "| h5netcdf               | 1.2.0       |\n",
        "| ipykernel              | 6.29.5      |\n",
        "| ipython                | 8.26.0      |\n",
        "| ipywidgets             | 8.1.3       |\n",
        "| jedi                   | 0.19.1      |\n",
        "| Jinja2                 | 3.1.4       |\n",
        "| jupyter_client         | 8.6.2       |\n",
        "| jupyter_core           | 5.7.2       |\n",
        "| jupyterlab_widgets     | 3.0.11      |\n",
        "| kiwisolver             | 1.4.5       |\n",
        "| MarkupSafe             | 2.1.5       |\n",
        "| matplotlib             | 3.9.1.post1 |\n",
        "| matplotlib-inline      | 0.1.7       |\n",
        "| nest-asyncio           | 1.6.0       |\n",
        "| NetCDF                 | 4.9.2       |\n",
        "| netCDF4                | 1.7.1.post1 |\n",
        "| numpy                  | 1.26.4      |\n",
        "| packaging              | 24.1        |\n",
        "| pandas                 | 2.2.2       |\n",
        "| parso                  | 0.8.4       |\n",
        "| pexpect                | 4.9.0       |\n",
        "| pillow                 | 10.4.0      |\n",
        "| pip                    | 24.2        |\n",
        "| platformdirs           | 4.2.2       |\n",
        "| prompt_toolkit         | 3.0.47      |\n",
        "| psutil                 | 6.0.0       |\n",
        "| ptyprocess             | 0.7.0       |\n",
        "| pure_eval              | 0.2.3       |\n",
        "| Pygments               | 2.18.0      |\n",
        "| pyparsing              | 3.1.2       |\n",
        "| pyproj                 | 3.6.1       |\n",
        "| pyshp                  | 2.3.1       |\n",
        "| python-dateutil        | 2.9.0.post0 |\n",
        "| pytz                   | 2024.1      |\n",
        "| pyzmq                  | 26.1.0      |\n",
        "| scipy                  | 1.14.0      |\n",
        "| setuptools             | 65.5.0      |\n",
        "| shapely                | 2.0.5       |\n",
        "| six                    | 1.16.0      |\n",
        "| stack-data             | 0.6.3       |\n",
        "| tabulate               | 0.9.0       |\n",
        "| tornado                | 6.4.1       |\n",
        "| traitlets              | 5.14.3      |\n",
        "| typing_extensions      | 4.12.2      |\n",
        "| tzdata                 | 2024.1      |\n",
        "| wcwidth                | 0.2.13      |\n",
        "| widgetsnbextension     | 4.0.11      |\n",
        "| xarray                 | 2024.7.0    |\n",
        "| lisvap                 | [https://ec-jrc.github.io/lisflood-lisvap/3_LISVAP_installation/]    | \n",
        "| pcraster               | 4.4.1 [https://pcraster.geo.uu.nl/pcraster/4.4.1/documentation/pcraster_project/install.html]       | "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "for y in {2023..2024}\n",
        "do\n",
        "    year=\"$y\"\n",
        "    year_n=\"$((y+1))\"\n",
        "    i1=\"${output_dir}/step_1/ERA5Land_${year}_1.grib\"\n",
        "    i2=\"${output_dir}/step_1/ERA5Land_${year}_2.grib\"\n",
        "    i3=\"${output_dir}/step_1/ERA5Land_${year}_3.grib\"\n",
        "    i4=\"${output_dir}/step_1/ERA5Land_${year}_4.grib\"\n",
        "    i5=\"${output_dir}/step_1/ERA5Land_${year}_5.grib\"\n",
        "    i6=\"${output_dir}/step_1/ERA5Land_${year}_6.grib\"\n",
        "    i7=\"${output_dir}/step_1/ERA5Land_${year}_7.grib\"\n",
        "    i8=\"${output_dir}/step_1/ERA5Land_${year}_8.grib\"\n",
        "    i9=\"${output_dir}/step_1/ERA5Land_${year}_9.grib\"\n",
        "    i10=\"${output_dir}/step_1/ERA5Land_${year}_10.grib\"\n",
        "    i11=\"${output_dir}/step_1/ERA5Land_${year}_11.grib\"\n",
        "    i12=\"${output_dir}/step_1/ERA5Land_${year}_12.grib\"\n",
        "    i13=\"${output_dir}/step_1/ERA5Land_${year_n}_1.grib\"\n",
        "    o_tas=\"${output_dir}/step_2/ERA5_land_daily/tas_ERA5_${year}.nc\"\n",
        "    o_tasmin=\"${output_dir}/step_2/ERA5_land_daily/tasmin_ERA5_${year}.nc\"\n",
        "    o_tasmax=\"${output_dir}/step_2/ERA5_land_daily/tasmax_ERA5_${year}.nc\"\n",
        "    o_t_dew=\"${output_dir}/step_2/ERA5_land_daily/dew_ERA5_${year}.nc\"\n",
        "    o_sfcWind=\"${output_dir}/step_2/ERA5_land_daily/sfcWind_ERA5_${year}.nc\"\n",
        "    o_rsds=\"${output_dir}/step_2/ERA5_land_daily/rsds_ERA5_${year}.nc\"\n",
        "    o_pr=\"${output_dir}/step_2/ERA5_land_daily/pr_ERA5_${year}.nc\"\n",
        "    o_rsds_t=\"${output_dir}/step_2/ERA5_land_daily/rsds_t_ERA5_${year}.nc\"\n",
        "    o_pr_t=\"${output_dir}/step_2/ERA5_land_daily/pr_t_ERA5_${year}.nc\"\n",
        "    o_hurs=\"${output_dir}/step_2/ERA5_land_daily/hurs_ERA5_${year}.nc\"\n",
        "\n",
        "    cdo -f nc -daymean -selname,var167 -mergetime $i1 $i2 $i3 $i4 $i5 $i6 $i7 $i8 $i9 $i10 $i11 $i12 $o_tas\n",
        "    cdo -f nc -daymin -selname,var167 -mergetime $i1 $i2 $i3 $i4 $i5 $i6 $i7 $i8 $i9 $i10 $i11 $i12 $o_tasmin\n",
        "    cdo -f nc -daymax -selname,var167 -mergetime $i1 $i2 $i3 $i4 $i5 $i6 $i7 $i8 $i9 $i10 $i11 $i12 $o_tasmax\n",
        "    cdo -f nc expr,rsds=\"var169/86400\" -selhour,0 -selname,var169 -mergetime $i1 $i2 $i3 $i4 $i5 $i6 $i7 $i8 $i9 $i10 $i11 $i12 $i13 $o_rsds_t\n",
        "    cdo -f nc expr,pr=\"var228/86.4\" -selhour,0 -selname,var228 -mergetime $i1 $i2 $i3 $i4 $i5 $i6 $i7 $i8 $i9 $i10 $i11 $i12 $i13 $o_pr_t\n",
        "    cdo selyear,$y -shifttime,-1days $o_rsds_t $o_rsds\n",
        "    cdo selyear,$y -shifttime,-1days $o_pr_t $o_pr\n",
        "    cdo -f nc -daymean -selname,var168,var167 -mergetime $i1 $i2 $i3 $i4 $i5 $i6 $i7 $i8 $i9 $i10 $i11 $i12 $o_t_dew\n",
        "    cdo expr,hurs=\"(10 ^ (7.5 * (var168-273.15) / (237.3+(var168-273.15)))) / (10 ^ (7.5 * (var167-273.15) / (237.3+(var167-273.15)))) * 100\" $o_t_dew $o_hurs\n",
        "    cdo -f nc expr,sfcWind=\"sqrt(var165*var165+var166*var166)\" -daymean -selname,var165,var166 -mergetime $i1 $i2 $i3 $i4 $i5 $i6 $i7 $i8 $i9 $i10 $i11 $i12 $o_sfcWind\n",
        "    rm $o_rsds_t\n",
        "    rm $o_pr_t\n",
        "    rm $o_t_dew\n",
        "\n",
        "done\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Possible error with nco "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_times=$(cdo ntime $filename)\n",
        "ncpdq -4 -O --cnk_plc=g3d --cnk_dmn=time,$n_times --cnk_dmn=lat,$n_lats --cnk_dmn=lon,$n_lons -a lon,lat,time $filename \"${output_dir}/step_5/ERA5_$(basename \"$filename\" .nc).nc\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "**Error in terminal:** *ncpdq: ERROR received 9 positional filenames; need exactly two*\n",
        "\n",
        "**How to fix:** \n",
        "Add after ncpdq\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "echo \"n_times: $n_times\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "run script and check results. \n",
        "Correct value should display one line, eg.: *n_times: 365*\n",
        "\n",
        "If you see another line below value:\n",
        "\n",
        "> *n_times: 365* \n",
        "\n",
        "> *cdo ntime: Processed 1 variable [0.01s 44MB].*\n",
        "\n",
        "add to n_time definition code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_times=$(cdo ntime $filename  | awk 'NR==1 {print $1}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2. If you are getting an error in step 7 for `tas` variable not found in the data, follow the below steps:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. First verify if the variable name is var167 by running the code snippet below in your terminal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ncdump -h input_file.nc #replace input file with the tas file that you want to rename"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Use `ncrename` function from `cdo` library to rename the variable from `var167` to `tas`. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ncrename -v old_varname,new_varname input_file.nc #replace input file with the tas file that you want to rename"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Run the script now and it should work. If not, re-check using ncdump -h your_file.nc to verify if variable is correctly renamed to `tas`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.3. Visualizing the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It is recommended that you visualize the data after completion of each step to verify if the data is being correctly produced. The data can be visualized by use of **ArcGIS** or **QGIS** or by utilizing below Python script."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from netCDF4 import Dataset\n",
        "\n",
        "def plot_nc_variable(nc_file, var_name, time_idx=1024):\n",
        "    dataset = Dataset(nc_file, 'r')\n",
        "    if var_name not in dataset.variables:\n",
        "        print(f\"Variable '{var_name}' not found in {nc_file}.\")\n",
        "        return\n",
        "    var_data = dataset.variables[var_name]\n",
        "    data = var_data[:, :, time_idx].T  \n",
        "    lats = dataset.variables['lat'][:]\n",
        "    lons = dataset.variables['lon'][:]\n",
        "\n",
        "    lon_grid, lat_grid = np.meshgrid(lons, lats)\n",
        "\n",
        "    # Plot the data\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.contourf(lon_grid, lat_grid, data, cmap='viridis')\n",
        "    plt.colorbar(label=f\"{var_name}\")\n",
        "    plt.xlabel('Longitude')\n",
        "    plt.ylabel('Latitude')\n",
        "    plt.title(f\"{var_name} at time index {time_idx}\")\n",
        "    plt.show()\n",
        "    dataset.close()\n",
        "\n",
        "nc_file = '${output_dir}/ERA5_tasrange_ERA5_1990_2022_t.nc'\n",
        "var_name = 'tasrange'\n",
        "plot_nc_variable(nc_file, var_name, time_idx=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.4. Memory error in Step 9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you encounter crashes in Python/Jupyter during Step 9 due to insufficient memory, ensure that your system has at least 32 GB of RAM. Should the issue persist, close all active Python/Jupyter instances or restart your computer and attempt running the script again.\n",
        "\n",
        "To mitigate memory constraints, consider dividing the script into smaller segments and running them individually, except for the temperature and vapor pressure/humidity sections, which must be executed together. However, for optimal performance and to prevent memory-related issues, it is recommended to run the script on a machine or external server with 64 GB or more of RAM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.5. Troubleshooting in Step 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To diagnose issues in Step 10, several commands can help identify where the problem arises, particularly related to timestamps, incorrect variables, or inconsistencies in variable units.\n",
        "\n",
        "1. Retain Temporary Files: Remove the final command in the code that deletes temporary files for specific variables. These files are valuable for troubleshooting. For each variable, four temporary files will be generated with the following naming convention: varname_b, varname_c, varname_d.\n",
        "\n",
        "2. Use CDO Info: Apply the cdo info command to each temporary file to pinpoint where the issue occurs.\n",
        "\n",
        "3. Verify Previous Steps: Review the earlier steps to ensure all were completed correctly. If any steps were performed incorrectly, repeat them and then re-execute Step 10.\n",
        "\n",
        "The most likely issue may be related to timestamps or inconsistent units. These can be resolved manually in Step 10 by adjusting the minutes or ensuring the units are consistent with the EMO-1 data."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "nco",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
